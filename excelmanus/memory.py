"""对话记忆模块：管理多轮对话上下文与 token 截断。"""

from __future__ import annotations

import logging
from pathlib import Path

import tiktoken

from excelmanus.config import ExcelManusConfig

logger = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# 默认系统提示词：从 prompts/ 文件加载，缺失时自动补齐
# ---------------------------------------------------------------------------


def _load_system_prompt() -> str:
    """从 PromptComposer 加载系统提示词。

    若 prompts/core/ 目录缺失或文件不全，PromptComposer 会自动补齐后加载。
    """
    from excelmanus.prompt_composer import PromptComposer, PromptContext
    prompts_dir = Path(__file__).resolve().parent / "prompts"
    composer = PromptComposer(prompts_dir)
    composer.load_all()
    ctx = PromptContext(write_hint="unknown")
    return composer.compose_text(ctx)


_DEFAULT_SYSTEM_PROMPT = _load_system_prompt()


class TokenCounter:
    """基于 tiktoken 的 token 计数器。

    使用 cl100k_base 编码（GPT-4 系列），对 Qwen 等模型也能提供
    比字符估算更准确的近似值，用于 memory 截断判断。
    """

    _encoding = tiktoken.get_encoding("cl100k_base")

    @staticmethod
    def count(text: str) -> int:
        """计算文本的 token 数量。"""
        if not text:
            return 0
        return len(TokenCounter._encoding.encode(text))

    @staticmethod
    def count_message(message: dict) -> int:
        """计算单条消息的 token 数量（含结构开销）。"""
        tokens = 4  # 每条消息的固定开销（role、分隔符等）
        for key, value in message.items():
            if value is None:
                continue
            if isinstance(value, str):
                tokens += TokenCounter.count(value)
            elif isinstance(value, list):
                # tool_calls 列表：序列化后计算
                tokens += TokenCounter.count(str(value))
        return tokens


class ConversationMemory:
    """对话记忆管理器。

    职责：
    - 维护有序的消息列表
    - 提供 system prompt 始终在首位的消息序列
    - 当 token 总量接近上下文窗口限制时，截断最早的对话记录
    """

    def __init__(self, config: ExcelManusConfig) -> None:
        self._messages: list[dict] = []
        self._system_prompt: str = _DEFAULT_SYSTEM_PROMPT
        self._max_context_tokens: int = config.max_context_tokens
        self._token_counter = TokenCounter()
        # 预留 10% 的 token 空间给模型输出
        self._truncation_threshold = int(self._max_context_tokens * 0.9)

    @property
    def system_prompt(self) -> str:
        """获取当前系统提示词。"""
        return self._system_prompt

    @system_prompt.setter
    def system_prompt(self, value: str) -> None:
        """设置系统提示词。"""
        self._system_prompt = value

    def add_user_message(self, content: str) -> None:
        """添加用户消息。"""
        self._messages.append({"role": "user", "content": content})
        self._truncate_if_needed()

    def add_assistant_message(self, content: str) -> None:
        """添加助手纯文本回复。"""
        self._messages.append({"role": "assistant", "content": content})
        self._truncate_if_needed()

    def add_tool_call(self, tool_call_id: str, name: str, arguments: str) -> None:
        """添加助手的工具调用消息。"""
        self._messages.append({
            "role": "assistant",
            "content": None,
            "tool_calls": [
                {
                    "id": tool_call_id,
                    "type": "function",
                    "function": {"name": name, "arguments": arguments},
                }
            ],
        })
        self._truncate_if_needed()

    def add_assistant_tool_message(self, message: dict) -> None:
        """添加完整的 assistant tool 调用消息。

        用于保留供应商返回的扩展字段（如 reasoning / 思维链相关元数据）。
        """
        normalized = dict(message)
        normalized["role"] = "assistant"
        self._messages.append(normalized)
        self._truncate_if_needed()

    def add_tool_result(self, tool_call_id: str, content: str) -> None:
        """添加工具执行结果消息。"""
        self._messages.append({
            "role": "tool",
            "tool_call_id": tool_call_id,
            "content": content,
        })
        self._truncate_if_needed()

    def _build_system_messages(self, system_prompts: list[str] | None = None) -> list[dict]:
        """构建 system 消息列表。"""
        prompts = system_prompts or [self._system_prompt]
        system_msgs = [
            {"role": "system", "content": prompt}
            for prompt in prompts
            if isinstance(prompt, str) and prompt.strip()
        ]
        if not system_msgs:
            system_msgs = [{"role": "system", "content": self._system_prompt}]
        return system_msgs

    def get_messages(self, system_prompts: list[str] | None = None) -> list[dict]:
        """获取完整消息列表（system prompt + 对话历史）。

        Args:
            system_prompts:
                可选的 system 消息列表；为空时使用默认 system prompt。
        """
        system_msgs = self._build_system_messages(system_prompts)
        return system_msgs + list(self._messages)

    def trim_for_request(
        self,
        system_prompts: list[str],
        max_context_tokens: int,
        reserve_ratio: float = 0.1,
    ) -> list[dict]:
        """按最终请求消息预算裁剪历史，返回可直接发送的消息列表。"""
        if max_context_tokens <= 0:
            return self.get_messages(system_prompts=system_prompts)
        ratio = reserve_ratio
        if ratio < 0:
            ratio = 0
        elif ratio >= 1:
            ratio = 0.99
        threshold = max(1, int(max_context_tokens * (1 - ratio)))
        system_msgs = self._build_system_messages(system_prompts)
        self._truncate_history_to_threshold(threshold, system_msgs=system_msgs)
        return system_msgs + list(self._messages)

    def clear(self) -> None:
        """清除所有对话历史（保留 system prompt 配置）。"""
        self._messages.clear()

    def _total_tokens(self) -> int:
        """计算当前所有消息（含 system prompt）的总 token 数。"""
        system_msg = {"role": "system", "content": self._system_prompt}
        total = self._token_counter.count_message(system_msg)
        for msg in self._messages:
            total += self._token_counter.count_message(msg)
        return total

    def _truncate_if_needed(self) -> None:
        """当 token 总量超过阈值时，从最早的消息开始截断。

        截断策略：
        1. 始终保留 system prompt（不在 _messages 中，由 get_messages 拼接）
        2. 从 _messages 头部逐条移除最早的消息
        3. 跳过孤立的 tool 结果消息（确保 tool_call 和 tool_result 成对移除）
        """
        self._truncate_history_to_threshold(self._truncation_threshold, system_msgs=None)

    def _total_tokens_with_system_messages(self, system_msgs: list[dict] | None) -> int:
        total = 0
        if system_msgs is None:
            system_msg = {"role": "system", "content": self._system_prompt}
            total += self._token_counter.count_message(system_msg)
        else:
            for msg in system_msgs:
                total += self._token_counter.count_message(msg)
        for msg in self._messages:
            total += self._token_counter.count_message(msg)
        return total

    def _truncate_history_to_threshold(
        self,
        threshold: int,
        system_msgs: list[dict] | None,
    ) -> None:
        while self._messages and self._total_tokens_with_system_messages(system_msgs) > threshold:
            # 仅剩最后一条时做内容收缩，避免单条超长消息长期越阈值。
            if len(self._messages) == 1:
                if not self._shrink_last_message_for_threshold(threshold, system_msgs):
                    # 无法收缩（例如 content 为 None 的 tool_call 壳消息）时，
                    # 直接丢弃最后一条，保证请求不会持续超预算。
                    self._messages.pop(0)
                    break
                continue

            # 移除最早的消息，但至少保留最后一条（最近的消息）
            removed = self._messages.pop(0)

            # 如果移除的是带 tool_calls 的 assistant 消息，
            # 需要同时移除对应的 tool result 消息
            if removed.get("tool_calls"):
                call_ids = {
                    tc["id"] for tc in removed["tool_calls"] if "id" in tc
                }
                # 移除所有匹配的 tool result（它们紧跟在 tool_call 之后）
                self._messages = [
                    m for m in self._messages
                    if not (
                        m.get("role") == "tool"
                        and m.get("tool_call_id") in call_ids
                    )
                ]

            # 如果最早的消息是孤立的 tool result（对应的 tool_call 已不存在），
            # 继续移除以保持消息一致性。
            # 注意：必须检查 tool_call_id 是否真的孤立，避免误删有效的 tool result。
            while self._messages and self._messages[0].get("role") == "tool":
                # 收集剩余消息中所有有效的 tool_call id
                valid_call_ids: set[str] = {
                    tc["id"]
                    for m in self._messages
                    if m.get("tool_calls")
                    for tc in m["tool_calls"]
                    if "id" in tc
                }
                head_call_id = self._messages[0].get("tool_call_id")
                if head_call_id in valid_call_ids:
                    # 对应的 tool_call 仍存在，不是孤立消息，停止清理
                    break
                self._messages.pop(0)

    def _shrink_last_message_for_threshold(
        self,
        threshold: int,
        system_msgs: list[dict] | None,
    ) -> bool:
        """尽量收缩最后一条消息内容，返回是否完成收缩。"""
        msg = self._messages[-1]
        content = msg.get("content")
        if not isinstance(content, str) or not content:
            return False

        message_tokens = self._token_counter.count_message(msg)
        content_tokens = self._token_counter.count(content)
        base_tokens = message_tokens - content_tokens
        budget_for_content = threshold - (
            self._total_tokens_with_system_messages(system_msgs) - message_tokens
        ) - base_tokens
        if budget_for_content <= 0:
            msg["content"] = ""
            return True

        if content_tokens <= budget_for_content:
            return True

        marker = "[截断]"

        def _fits(candidate: str) -> bool:
            return self._token_counter.count(candidate) <= budget_for_content

        # 二分查找可保留的最大尾部长度，避免字符近似导致过度裁切。
        left = 1
        right = len(content)
        best = ""
        while left <= right:
            mid = (left + right) // 2
            candidate = f"{marker}{content[-mid:]}"
            if _fits(candidate):
                best = candidate
                left = mid + 1
            else:
                right = mid - 1

        if not best:
            # 如果加标记放不下，退化为纯尾部文本，尽量保留一点近期上下文。
            left = 1
            right = len(content)
            while left <= right:
                mid = (left + right) // 2
                candidate = content[-mid:]
                if _fits(candidate):
                    best = candidate
                    left = mid + 1
                else:
                    right = mid - 1

        if not best:
            msg["content"] = ""
            return True

        if len(best) >= len(content):
            best = content[-max(1, len(content) // 2):]

        # 防止收缩后内容未变导致外层 while 无限循环
        if best == content:
            msg["content"] = ""
            return True

        msg["content"] = best
        return True
