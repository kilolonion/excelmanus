"""ContextBuilder â€” ä» AgentEngine è§£è€¦çš„ç³»ç»Ÿæç¤ºè¯ç»„è£…ç»„ä»¶ã€‚

è´Ÿè´£ç®¡ç†ï¼š
- ç³»ç»Ÿæç¤ºè¯ç»„è£…ï¼ˆ_prepare_system_prompts_for_requestï¼‰
- å„ç±» notice æ„å»ºï¼ˆaccess/backup/mcp/window/tool_indexï¼‰
- å·¥å…·ååˆ—è¡¨ã€çª—å£æ„ŸçŸ¥æç¤ºè®¾ç½®
"""

from __future__ import annotations

import hashlib as _hashlib
import json as _json
from collections.abc import Sequence
from typing import TYPE_CHECKING, Any

from excelmanus.logger import get_logger
from excelmanus.mcp.manager import parse_tool_prefix
from excelmanus.memory import TokenCounter
from excelmanus.task_list import TaskStatus

if TYPE_CHECKING:
    from excelmanus.engine import AgentEngine
    from excelmanus.events import EventCallback
    from excelmanus.skillpacks import SkillMatchResult

_MAX_PLAN_AUTO_CONTINUE = 3  # è®¡åˆ’å®¡æ‰¹åè‡ªåŠ¨ç»­è·‘æœ€å¤§æ¬¡æ•°
_PLAN_CONTEXT_MAX_CHARS = 6000
_MIN_SYSTEM_CONTEXT_CHARS = 256
_SYSTEM_CONTEXT_SHRINK_MARKER = "[ä¸Šä¸‹æ–‡å·²å‹ç¼©ä»¥é€‚é…ä¸Šä¸‹æ–‡çª—å£]"

logger = get_logger("context_builder")


class ContextBuilder:
    """ç³»ç»Ÿæç¤ºè¯ç»„è£…å™¨ï¼Œä» AgentEngine æ¬è¿æ‰€æœ‰ _build_*_notice å’Œ _prepare_system_promptsã€‚"""

    _TOKEN_COUNT_CACHE_MAX = 16  # fingerprint â†’ token_count LRU ä¸Šé™

    def __init__(self, engine: "AgentEngine") -> None:
        self._engine = engine
        # O3+O4: åŸºäºå†…å®¹æŒ‡çº¹çš„ token è®¡æ•°ç¼“å­˜ï¼Œé¿å…é‡å¤ tiktoken ç¼–ç 
        self._token_count_cache: dict[str, int] = {}

    def _all_tool_names(self) -> list[str]:
        e = self._engine
        get_tool_names = getattr(e.registry, "get_tool_names", None)
        if callable(get_tool_names):
            return list(get_tool_names())

        get_all_tools = getattr(e.registry, "get_all_tools", None)
        if callable(get_all_tools):
            return [tool.name for tool in get_all_tools()]

        return []

    def _focus_window_refill_reader(
        self,
        *,
        file_path: str,
        sheet_name: str,
        range_ref: str,
    ) -> dict[str, Any]:
        """focus_window è‡ªåŠ¨è¡¥è¯»å›è°ƒã€‚"""
        e = self._engine
        if not file_path or not sheet_name or not range_ref:
            return {"success": False, "error": "ç¼ºå°‘ file_path/sheet_name/range å‚æ•°"}

        all_tools = self._all_tool_names()
        read_sheet_tools: list[str] = []
        for tool_name in all_tools:
            if not tool_name.startswith("mcp_"):
                continue
            try:
                _, origin_name = parse_tool_prefix(tool_name)
            except ValueError:
                continue
            if origin_name == "read_sheet":
                read_sheet_tools.append(tool_name)

        for tool_name in read_sheet_tools:
            try:
                arguments = {
                    "file_path": file_path,
                    "sheet_name": sheet_name,
                    "range": range_ref,
                }
                result_text = str(
                    e.registry.call_tool(
                        tool_name,
                        arguments,
                    )
                )
                return {
                    "success": True,
                    "tool_name": tool_name,
                    "arguments": arguments,
                    "result_text": result_text,
                }
            except Exception:
                continue

        if "read_excel" in all_tools:
            arguments: dict[str, Any] = {"file_path": file_path, "sheet_name": sheet_name}
            try:
                from openpyxl.utils.cell import range_boundaries

                _, min_row, _, max_row = range_boundaries(range_ref)
                arguments["max_rows"] = max(1, int(max_row) - int(min_row) + 1)
            except Exception:
                pass
            try:
                result_text = str(
                    e.registry.call_tool(
                        "read_excel",
                        arguments,
                    )
                )
                return {
                    "success": True,
                    "tool_name": "read_excel",
                    "arguments": arguments,
                    "result_text": result_text,
                }
            except Exception as exc:
                return {"success": False, "error": f"è¡¥è¯»å¤±è´¥: {exc}"}

        return {"success": False, "error": "æœªæ‰¾åˆ°å¯ç”¨è¯»å–å·¥å…·ï¼ˆread_sheet/read_excelï¼‰"}


    @staticmethod
    def _system_prompts_token_count(system_prompts: Sequence[str]) -> int:
        total = 0
        for prompt in system_prompts:
            total += TokenCounter.count_message({"role": "system", "content": prompt})
        return total

    @staticmethod
    def _shrink_context_text(text: str) -> str:
        normalized = (text or "").strip()
        if not normalized:
            return ""
        if len(normalized) <= _MIN_SYSTEM_CONTEXT_CHARS:
            return ""
        keep_chars = max(_MIN_SYSTEM_CONTEXT_CHARS, len(normalized) // 2)
        shrinked = normalized[:keep_chars].rstrip()
        if _SYSTEM_CONTEXT_SHRINK_MARKER in shrinked:
            return shrinked
        return f"{shrinked}\n{_SYSTEM_CONTEXT_SHRINK_MARKER}"

    @staticmethod
    def _minimize_skill_context(text: str) -> str:
        lines = [line for line in str(text or "").splitlines() if line.strip()]
        if not lines:
            return ""
        head = lines[0]
        second = lines[1] if len(lines) > 1 else ""
        minimal_parts = [head]
        if second:
            minimal_parts.append(second)
        minimal_parts.append("[Skillpack æ­£æ–‡å·²çœç•¥ä»¥é€‚é…ä¸Šä¸‹æ–‡çª—å£]")
        return "\n".join(minimal_parts)

    def _build_rules_notice(self) -> str:
        """ç»„è£…ç”¨æˆ·è‡ªå®šä¹‰è§„åˆ™æ–‡æœ¬ï¼Œæ³¨å…¥ system promptã€‚"""
        e = self._engine
        rm = getattr(e, "_rules_manager", None)
        if rm is None:
            return ""
        session_id = getattr(e, "_session_id", None)
        try:
            return rm.compose_rules_prompt(session_id)
        except Exception:
            logger.debug("è§„åˆ™æ³¨å…¥å¤±è´¥", exc_info=True)
            return ""

    def _build_meta_cognition_notice(self) -> str:
        """æ¡ä»¶æ€§æ³¨å…¥è¿›å±•åæ€æç¤ºï¼Œå¸®åŠ© agent åœ¨å›°å¢ƒä¸­è°ƒæ•´ç­–ç•¥ã€‚

        çµæ„Ÿæ¥æºï¼šMetacognition is All You Need è®ºæ–‡ã€‚
        ä»…åœ¨ç‰¹å®šé€€åŒ–æ¡ä»¶ä¸‹è§¦å‘ï¼ˆæ¥è¿‘è¿­ä»£ä¸Šé™ / è¿ç»­å¤±è´¥ / æ‰§è¡Œå®ˆå«å·²è§¦å‘ï¼‰ï¼Œ
        å¦åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²ï¼ˆé›¶ token å¼€é”€ï¼‰ã€‚
        """
        e = self._engine
        state = e.state
        max_iter = e.config.max_iterations
        iteration = state.last_iteration_count
        failures = state.last_failure_count
        successes = state.last_success_count

        parts: list[str] = []
        _MAX_WARNINGS = 2

        # æ¡ä»¶ 1ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰ï¼šæ¥è¿‘è¿­ä»£ä¸Šé™ï¼ˆå·²ç”¨ >= 60%ï¼‰
        if max_iter > 0 and iteration >= max_iter * 0.6:
            parts.append(
                f"âš ï¸ æ¥è¿‘è¿­ä»£ä¸Šé™ï¼ˆ{iteration}/{max_iter}ï¼‰ï¼Œ"
                "è¯·å°½å¿«å®Œæˆä»»åŠ¡æˆ–è°ƒç”¨ ask_userã€‚"
            )

        # æ¡ä»¶ 2ï¼šè¿ç»­å¤±è´¥ >= 3
        if len(parts) < _MAX_WARNINGS and failures >= 3 and successes == 0:
            parts.append(
                f"âš ï¸ å·²è¿ç»­å¤±è´¥ {failures} æ¬¡ä¸”æ— æˆåŠŸè°ƒç”¨ã€‚å»ºè®®ï¼š"
                "1) æ£€æŸ¥æ–‡ä»¶è·¯å¾„å’Œ sheet åæ˜¯å¦æ­£ç¡® "
                "2) ç®€åŒ–æ“ä½œæ­¥éª¤ "
                "3) è°ƒç”¨ ask_user ç¡®è®¤ã€‚"
            )

        # æ¡ä»¶ 3ï¼šæ‰§è¡Œå®ˆå«æ›¾è§¦å‘ï¼ˆagent æ›¾ç»™å‡ºå»ºè®®è€Œä¸æ‰§è¡Œï¼‰
        if len(parts) < _MAX_WARNINGS and state.execution_guard_fired and not state.has_write_tool_call:
            parts.append(
                "âš ï¸ æ­¤å‰å·²è§¦å‘æ‰§è¡Œå®ˆå«ã€‚è¯·é€šè¿‡å·¥å…·æ‰§è¡Œæ“ä½œï¼Œä¸è¦ä»…ç»™å‡ºæ–‡æœ¬å»ºè®®ã€‚"
            )

        # æ¡ä»¶ 4ï¼ˆä¼˜å…ˆçº§æœ€ä½ï¼‰ï¼šæ²‰é»˜è°ƒç”¨
        silent = state.silent_call_count
        reasoned = state.reasoned_call_count
        if len(parts) < _MAX_WARNINGS and silent > 0 and silent >= reasoned:
            parts.append(
                f"âš ï¸ æœ¬è½®å·²æœ‰ {silent} æ¬¡å·¥å…·è°ƒç”¨æœªé™„å¸¦æ¨ç†æ–‡æœ¬ã€‚"
                "è¯·éµå¾ª Think-Act åè®®ï¼šå·¥å…·è°ƒç”¨å‰è‡³å°‘ç”¨ 1 å¥è¯è¯´æ˜æ„å›¾ã€‚"
                "ï¼ˆthinking æ¨¡å‹ï¼šæ¨ç†å¯åœ¨ thinking å—ä¸­å®Œæˆã€‚ï¼‰"
            )

        if not parts:
            return ""

        return "## è¿›å±•åæ€\n" + "\n".join(parts)

    @staticmethod
    def _compute_reasoning_level_static(route_result: Any) -> str:
        """æ ¹æ®ä»»åŠ¡ä¸Šä¸‹æ–‡è®¡ç®—æ¨èæ¨ç†çº§åˆ«ã€‚"""
        if route_result is None:
            return "standard"
        wh = getattr(route_result, "write_hint", "unknown") or "unknown"
        tags = set(getattr(route_result, "task_tags", []) or [])
        if wh == "read_only":
            return "lightweight"
        if tags & {"cross_sheet", "large_data"}:
            return "complete"
        if wh == "may_write":
            return "standard"
        return "lightweight"

    def _build_runtime_metadata_line(self) -> str:
        """ç”Ÿæˆç´§å‡‘çš„è¿è¡Œæ—¶å…ƒæ•°æ®è¡Œï¼Œè®© agent æ„ŸçŸ¥è‡ªèº«çŠ¶æ€ã€‚

        ä¸€è¡Œå³å¯è®© agent çŸ¥é“è‡ªå·±æ˜¯ä»€ä¹ˆæ¨¡å‹ã€å½“å‰è½®æ¬¡ã€æƒé™çŠ¶æ€ç­‰ã€‚
        """
        e = self._engine
        parts: list[str] = [
            f"model={e.active_model}",
            f"turn={e._session_turn}/{e.config.max_iterations}",
            f"write_hint={e.state.current_write_hint}",
            f"fullaccess={'on' if e.full_access_enabled else 'off'}",
            f"backup={'on' if e.workspace.transaction_enabled else 'off'}",
            f"mcp={e.mcp_connected_count}",
            f"subagent={'on' if e._subagent_enabled else 'off'}",
            f"vision={'on' if e._is_vision_capable else 'off'}",
            f"chat_mode={getattr(e, '_current_chat_mode', 'write')}",
            f"skills={len(e._active_skills)}",
        ]
        if e.workspace_manifest is not None:
            parts.append(f"files={e.workspace_manifest.total_files}")
        _route = getattr(e, '_last_route_result', None)
        parts.append(f"reasoning={self._compute_reasoning_level_static(_route)}")
        return "Runtime: " + " | ".join(parts)

    def _prepare_system_prompts_for_request(
        self,
        skill_contexts: list[str],
        *,
        route_result: SkillMatchResult | None = None,
    ) -> tuple[list[str], str | None]:
        """æ„å»ºç”¨äºæœ¬è½®è¯·æ±‚çš„ system promptsï¼Œå¹¶åœ¨å¿…è¦æ—¶å‹ç¼©ä¸Šä¸‹æ–‡ã€‚

        Prompt Cache ä¼˜åŒ–ï¼šé™æ€å†…å®¹ï¼ˆidentity promptã€è§„åˆ™ã€æƒé™ç­‰ï¼‰æ”¾åœ¨å‰é¢ï¼Œ
        åŠ¨æ€å†…å®¹ï¼ˆruntime_metadataã€meta_cognition ç­‰ï¼‰æ”¾åœ¨æœ«å°¾ï¼Œ
        ç¡®ä¿ Anthropic prompt caching çš„å‰ç¼€ç¨³å®šæ€§ã€‚
        """
        e = self._engine
        base_prompt = e.memory.system_prompt

        # â”€â”€ é™æ€/åŠé™æ€å†…å®¹ï¼ˆå‰ç¼€åŒºåŸŸï¼Œæœ€å¤§åŒ– cache å‘½ä¸­ï¼‰ â”€â”€

        rules_notice = self._build_rules_notice()
        if rules_notice:
            base_prompt = base_prompt + "\n\n" + rules_notice

        access_notice = e._build_access_notice()
        if access_notice:
            base_prompt = base_prompt + "\n\n" + access_notice

        backup_notice = e._build_backup_notice()
        if backup_notice:
            base_prompt = base_prompt + "\n\n" + backup_notice

        cow_path_notice = self._build_cow_path_notice()
        if cow_path_notice:
            base_prompt = base_prompt + "\n\n" + cow_path_notice

        mcp_context = e._build_mcp_context_notice()
        if mcp_context:
            base_prompt = base_prompt + "\n\n" + mcp_context

        workspace_manifest_notice = self._build_workspace_manifest_notice()
        if workspace_manifest_notice:
            base_prompt = base_prompt + "\n\n" + workspace_manifest_notice

        # æ³¨å…¥é¢„å–ä¸Šä¸‹æ–‡ï¼ˆexplorer å­ä»£ç†é¢„å–çš„æ–‡ä»¶æ‘˜è¦ï¼‰
        prefetch_context = getattr(e, "_prefetch_context", "") or ""
        if prefetch_context:
            base_prompt = base_prompt + "\n\n" + prefetch_context

        # â”€â”€ åŠé™æ€å†…å®¹ï¼ˆè½®æ¬¡çº§ç¨³å®šï¼Œæœ€å¤§åŒ– Provider prompt cache å‰ç¼€ï¼‰ â”€â”€

        # æ³¨å…¥ä»»åŠ¡ç­–ç•¥ï¼ˆPromptComposer strategiesï¼ŒåŒä¸€è½®æ¬¡å†…ä¸å˜ï¼‰
        _strategy_text_captured = ""
        if e._prompt_composer is not None and route_result is not None:
            try:
                from excelmanus.prompt_composer import PromptContext as _PCtx
                _p_ctx = _PCtx(
                    chat_mode=getattr(e, "_current_chat_mode", "write"),
                    write_hint=route_result.write_hint or "unknown",
                    sheet_count=route_result.sheet_count,
                    total_rows=route_result.max_total_rows,
                    task_tags=list(route_result.task_tags),
                    full_access=e.full_access_enabled,
                )
                _strategy_text = e._prompt_composer.compose_strategies_text(_p_ctx)
                if _strategy_text:
                    base_prompt = base_prompt + "\n\n" + _strategy_text
                    _strategy_text_captured = _strategy_text
            except Exception:
                logger.debug("ç­–ç•¥æ³¨å…¥å¤±è´¥ï¼Œè·³è¿‡", exc_info=True)

        # â”€â”€ åŠ¨æ€å†…å®¹ï¼ˆæ”¾åœ¨æœ€æœ«å°¾ï¼ŒProvider cache å‰ç¼€åˆ°æ­¤ä¸ºæ­¢ï¼‰ â”€â”€

        _hook_context_captured = ""
        if e._transient_hook_contexts:
            hook_context = "\n".join(e._transient_hook_contexts).strip()
            e._transient_hook_contexts.clear()
            if hook_context:
                base_prompt = base_prompt + "\n\n## Hook ä¸Šä¸‹æ–‡\n" + hook_context
                _hook_context_captured = hook_context

        # æ³¨å…¥è¿è¡Œæ—¶å…ƒæ•°æ®ï¼ˆæ¯è½®/æ¯è¿­ä»£å˜åŒ–ï¼Œæ”¾åœ¨æ‰€æœ‰é™æ€å†…å®¹ä¹‹åï¼‰
        runtime_line = self._build_runtime_metadata_line()
        base_prompt = base_prompt + "\n\n" + runtime_line

        # æ¡ä»¶æ€§æ³¨å…¥è¿›å±•åæ€ï¼ˆä»…åœ¨é€€åŒ–æ¡ä»¶ä¸‹è§¦å‘ï¼Œæ­£å¸¸æƒ…å†µé›¶å¼€é”€ï¼‰
        meta_cognition = self._build_meta_cognition_notice()
        if meta_cognition:
            base_prompt = base_prompt + "\n\n" + meta_cognition

        window_perception_context = self._build_window_perception_notice()
        window_at_tail = e._effective_window_return_mode() != "enriched"
        current_skill_contexts = [
            ctx for ctx in skill_contexts if isinstance(ctx, str) and ctx.strip()
        ]

        # â”€â”€ é‡‡é›†æç¤ºè¯æ³¨å…¥å¿«ç…§ â”€â”€
        _snapshot_components: dict[str, str] = {}
        if rules_notice:
            _snapshot_components["user_rules"] = rules_notice
        if access_notice:
            _snapshot_components["access_notice"] = access_notice
        if backup_notice:
            _snapshot_components["backup_notice"] = backup_notice
        if cow_path_notice:
            _snapshot_components["cow_path_notice"] = cow_path_notice
        if mcp_context:
            _snapshot_components["mcp_context"] = mcp_context
        if workspace_manifest_notice:
            _snapshot_components["workspace_manifest"] = workspace_manifest_notice
        if prefetch_context:
            _snapshot_components["prefetch_context"] = prefetch_context
        if runtime_line:
            _snapshot_components["runtime_metadata"] = runtime_line
        if _strategy_text_captured:
            _snapshot_components["prompt_strategies"] = _strategy_text_captured
        if _hook_context_captured:
            _snapshot_components["hook_context"] = _hook_context_captured
        if window_perception_context:
            _snapshot_components["window_perception_context"] = window_perception_context
        for idx, ctx in enumerate(current_skill_contexts):
            _snapshot_components[f"skill_context_{idx}"] = ctx

        _injection_summary: list[dict[str, Any]] = [
            {"name": name, "chars": len(text)}
            for name, text in _snapshot_components.items()
        ]
        _content_fingerprint = _hashlib.md5(
            _json.dumps(
                _snapshot_components, sort_keys=True, ensure_ascii=False,
            ).encode()
        ).hexdigest()[:12]

        _snapshots = e.state.prompt_injection_snapshots
        _last_fp = _snapshots[-1].get("_fingerprint") if _snapshots else None

        if _last_fp != _content_fingerprint:
            _snapshots.append({
                "session_turn": e._session_turn,
                "summary": _injection_summary,
                "total_chars": sum(len(t) for t in _snapshot_components.values()),
                "components": _snapshot_components,
                "_fingerprint": _content_fingerprint,
            })
        else:
            _snapshots.append({
                "session_turn": e._session_turn,
                "_ref": _content_fingerprint,
            })

        def _compose_prompts() -> list[str]:
            mode = e._effective_system_mode()
            if mode == "merge":
                merged_parts = [base_prompt]
                merged_parts.extend(current_skill_contexts)
                if window_perception_context:
                    if window_at_tail:
                        merged_parts.append(window_perception_context)
                    else:
                        merged_parts.insert(1, window_perception_context)
                return ["\n\n".join(merged_parts)]

            prompts = [base_prompt]
            if window_at_tail:
                prompts.extend(current_skill_contexts)
                if window_perception_context:
                    prompts.append(window_perception_context)
            else:
                if window_perception_context:
                    prompts.append(window_perception_context)
                prompts.extend(current_skill_contexts)
            return prompts

        threshold = max(1, int(e.config.max_context_tokens * 0.9))
        prompts = _compose_prompts()

        # O3+O4: åŸºäºå†…å®¹æŒ‡çº¹çš„ token è®¡æ•°ç¼“å­˜
        _cached_count = self._token_count_cache.get(_content_fingerprint)
        if _cached_count is not None:
            total_tokens = _cached_count
        else:
            total_tokens = self._system_prompts_token_count(prompts)
            # LRU æ·˜æ±°
            if len(self._token_count_cache) >= self._TOKEN_COUNT_CACHE_MAX:
                self._token_count_cache.pop(next(iter(self._token_count_cache)))
            self._token_count_cache[_content_fingerprint] = total_tokens

        if total_tokens <= threshold:
            return prompts, None

        if window_perception_context:
            window_perception_context = self._shrink_context_text(window_perception_context)
            prompts = _compose_prompts()
            total_tokens = self._system_prompts_token_count(prompts)
            if total_tokens <= threshold:
                return prompts, None
            window_perception_context = ""

        for idx in range(len(current_skill_contexts) - 1, -1, -1):
            minimized = self._minimize_skill_context(current_skill_contexts[idx])
            if minimized and minimized != current_skill_contexts[idx]:
                current_skill_contexts[idx] = minimized
                prompts = _compose_prompts()
                total_tokens = self._system_prompts_token_count(prompts)
                if total_tokens <= threshold:
                    return prompts, None

        while current_skill_contexts:
            current_skill_contexts.pop()
            prompts = _compose_prompts()
            total_tokens = self._system_prompts_token_count(prompts)
            if total_tokens <= threshold:
                return prompts, None

        if self._system_prompts_token_count(prompts) > threshold:
            return [], (
                "ç³»ç»Ÿä¸Šä¸‹æ–‡è¿‡é•¿ï¼Œå·²æ— æ³•åœ¨å½“å‰ä¸Šä¸‹æ–‡çª—å£å†…ç»§ç»­æ‰§è¡Œã€‚"
                "è¯·å‡å°‘é™„åŠ ä¸Šä¸‹æ–‡æˆ–æ‹†åˆ†ä»»åŠ¡åé‡è¯•ã€‚"
            )
        return prompts, None


    def _build_task_list_status_notice(self) -> str:
        """æ„å»ºå½“å‰ä»»åŠ¡æ¸…å•çŠ¶æ€æ‘˜è¦ï¼Œç”¨äºæ³¨å…¥ system promptã€‚"""
        e = self._engine
        task_list = e._task_store.current
        if task_list is None:
            return ""
        lines = [f"### ä»»åŠ¡æ¸…å•çŠ¶æ€ã€Œ{task_list.title}ã€"]
        for idx, item in enumerate(task_list.items):
            status_icon = {
                TaskStatus.PENDING: "ğŸ”µ",
                TaskStatus.IN_PROGRESS: "ğŸŸ¡",
                TaskStatus.COMPLETED: "âœ…",
                TaskStatus.FAILED: "âŒ",
            }.get(item.status, "â¬œ")
            lines.append(f"- {status_icon} #{idx} {item.title} ({item.status.value})")
        return "\n".join(lines)

    def _has_incomplete_tasks(self) -> bool:
        """æ£€æŸ¥ä»»åŠ¡æ¸…å•æ˜¯å¦å­˜åœ¨æœªå®Œæˆçš„å­ä»»åŠ¡ã€‚"""
        e = self._engine
        task_list = e._task_store.current
        if task_list is None:
            return False
        return any(
            item.status in (TaskStatus.PENDING, TaskStatus.IN_PROGRESS)
            for item in task_list.items
        )

    def _has_verification_failed_blocking_task(self) -> bool:
        """æ£€æŸ¥ä»»åŠ¡åºåˆ—ä¸­æ˜¯å¦æœ‰å¸¦éªŒè¯æ¡ä»¶çš„å¤±è´¥ä»»åŠ¡é˜»æ–­åç»­æ­¥éª¤ã€‚

        ä»…å½“å¤±è´¥ä»»åŠ¡å…·æœ‰ verification_criteria æ—¶è§†ä¸ºéªŒè¯å¤±è´¥é˜»æ–­ï¼›
        æ— éªŒè¯æ¡ä»¶çš„æ“ä½œå¤±è´¥ä¸é˜»æ–­ï¼ˆä¿æŒç°æœ‰å®¹é”™è¡Œä¸ºï¼‰ã€‚
        """
        e = self._engine
        task_list = e._task_store.current
        if task_list is None:
            return False
        for item in task_list.items:
            if item.status == TaskStatus.FAILED and item.verification_criteria:
                return True
            if item.status in (TaskStatus.PENDING, TaskStatus.IN_PROGRESS):
                break
        return False

    async def _auto_continue_task_loop(
        self,
        route_result: "SkillMatchResult",
        on_event: EventCallback | None,
        initial_result: ChatResult,
    ) -> ChatResult:
        """è®¡åˆ’å®¡æ‰¹åè‡ªåŠ¨ç»­è·‘ï¼šè‹¥ä»»åŠ¡æ¸…å•ä»æœ‰æœªå®Œæˆå­ä»»åŠ¡ï¼Œè‡ªåŠ¨æ³¨å…¥ç»­è·‘æ¶ˆæ¯ã€‚"""
        from excelmanus.engine import ChatResult
        e = self._engine
        result = initial_result
        for attempt in range(_MAX_PLAN_AUTO_CONTINUE):
            if not self._has_incomplete_tasks():
                break
            # éªŒè¯å¤±è´¥é˜»æ–­ï¼šå¸¦éªŒè¯æ¡ä»¶çš„ä»»åŠ¡å¤±è´¥æ—¶åœæ­¢ç»­è·‘
            if self._has_verification_failed_blocking_task():
                logger.info("è‡ªåŠ¨ç»­è·‘åœæ­¢ï¼šæ£€æµ‹åˆ°å¸¦éªŒè¯æ¡ä»¶çš„ä»»åŠ¡å¤±è´¥")
                break
            # é‡åˆ°å¾…ç¡®è®¤/å¾…å›ç­”/å¾…å®¡æ‰¹æ—¶ä¸ç»­è·‘ï¼Œäº¤è¿˜ç”¨æˆ·æ§åˆ¶
            if e.approval.has_pending():
                break
            if e._question_flow.has_pending():
                break
            if e._pending_plan is not None:
                break

            logger.info(
                "è‡ªåŠ¨ç»­è·‘ %d/%dï¼šä»»åŠ¡æ¸…å•ä»æœ‰æœªå®Œæˆå­ä»»åŠ¡",
                attempt + 1,
                _MAX_PLAN_AUTO_CONTINUE,
            )
            e.memory.add_user_message(
                "è¯·ç»§ç»­æ‰§è¡Œå‰©ä½™çš„æœªå®Œæˆå­ä»»åŠ¡ï¼Œç›´åˆ°å…¨éƒ¨å®Œæˆã€‚"
            )
            e._set_window_perception_turn_hints(
                user_message="ç»§ç»­æ‰§è¡Œå‰©ä½™å­ä»»åŠ¡",
                is_new_task=False,
            )
            resumed = await e._tool_calling_loop(route_result, on_event)
            result = ChatResult(
                reply=f"{result.reply}\n\n{resumed.reply}",
                tool_calls=list(result.tool_calls) + list(resumed.tool_calls),
                iterations=result.iterations + resumed.iterations,
                truncated=resumed.truncated,
                prompt_tokens=result.prompt_tokens + resumed.prompt_tokens,
                completion_tokens=result.completion_tokens + resumed.completion_tokens,
                total_tokens=result.total_tokens + resumed.total_tokens,
            )
        return result

    # å¯¹åŸå§‹æ–‡ä»¶æœ¬èº«æ‰§è¡Œç ´åæ€§æ“ä½œçš„å·¥å…·ã€‚
    # è¿™äº›å·¥å…·ç»•è¿‡å¤‡ä»½é‡å®šå‘ â€” å®¡æ‰¹é—¨ç¦å·²æä¾›å®‰å…¨ä¿éšœï¼Œ
    # é‡å®šå‘ä¼šé™é»˜åˆ›å»ºä¸€ä¸ªç”¨æˆ·ä»æœªæ‰“ç®—ä½¿ç”¨çš„ä¸€æ¬¡æ€§å¤‡ä»½å‰¯æœ¬ã€‚
    _DESTRUCTIVE_NO_REDIRECT_TOOLS = frozenset({"delete_file"})

    def _redirect_backup_paths(
        self,
        tool_name: str,
        arguments: dict[str, Any],
    ) -> dict[str, Any]:
        """å¤‡ä»½æ¨¡å¼ä¸‹é‡å®šå‘å·¥å…·å‚æ•°ä¸­çš„æ–‡ä»¶è·¯å¾„åˆ°å¤‡ä»½å‰¯æœ¬ã€‚"""
        e = self._engine
        tx = e.transaction
        if not e.workspace.transaction_enabled or tx is None:
            return arguments

        if tool_name in self._DESTRUCTIVE_NO_REDIRECT_TOOLS:
            return arguments

        from excelmanus.tools.policy import (
            AUDIT_TARGET_ARG_RULES_ALL,
            AUDIT_TARGET_ARG_RULES_FIRST,
            READ_ONLY_SAFE_TOOLS,
        )

        path_fields: list[str] = []
        all_fields = AUDIT_TARGET_ARG_RULES_ALL.get(tool_name)
        if all_fields is not None:
            path_fields.extend(all_fields)
        else:
            first_fields = AUDIT_TARGET_ARG_RULES_FIRST.get(tool_name)
            if first_fields is not None:
                path_fields.extend(first_fields)

        if tool_name in READ_ONLY_SAFE_TOOLS:
            for key in ("file_path", "path", "directory"):
                if key in arguments and key not in path_fields:
                    path_fields.append(key)

        if not path_fields:
            return arguments

        redirected = dict(arguments)
        for field_name in path_fields:
            raw = arguments.get(field_name)
            if raw is None:
                continue
            raw_str = str(raw).strip()
            if not raw_str:
                continue
            try:
                if tool_name in READ_ONLY_SAFE_TOOLS:
                    redirected[field_name] = tx.resolve_read(raw_str)
                else:
                    redirected[field_name] = tx.stage_for_write(raw_str)
            except ValueError:
                pass
        return redirected

    def _build_access_notice(self) -> str:
        """å½“ fullaccess å…³é—­æ—¶ï¼Œç”Ÿæˆæƒé™é™åˆ¶è¯´æ˜æ³¨å…¥ system promptã€‚"""
        e = self._engine
        if e.full_access_enabled:
            return ""
        restricted = e._restricted_code_skillpacks
        if not restricted:
            return ""
        skill_list = "ã€".join(sorted(restricted))
        return (
            f"ã€æƒé™æç¤ºã€‘å½“å‰ fullaccess æƒé™å¤„äºå…³é—­çŠ¶æ€ã€‚"
            f"ä»¥ä¸‹æŠ€èƒ½éœ€è¦ fullaccess æƒé™æ‰èƒ½æ¿€æ´»ï¼š{skill_list}ã€‚"
            f"æ³¨æ„ï¼šrun_code å·¥å…·å·²é…å¤‡ä»£ç ç­–ç•¥å¼•æ“ï¼ˆè‡ªåŠ¨é£é™©åˆ†çº§ + è¿è¡Œæ—¶æ²™ç›’ï¼‰ï¼Œ"
            f"å®‰å…¨ä»£ç ï¼ˆGREEN/YELLOW ç­‰çº§ï¼‰å¯ç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€ fullaccess æƒé™ã€‚"
            f"ä»…æ¶‰åŠé«˜é£é™©æ“ä½œï¼ˆå¦‚ subprocessã€execï¼‰çš„ä»£ç éœ€è¦ç”¨æˆ·ç¡®è®¤ã€‚"
        )

    def _build_backup_notice(self) -> str:
        """å¤‡ä»½æ¨¡å¼ï¼ˆworkspace transactionï¼‰å¯ç”¨æ—¶ï¼Œç”Ÿæˆæç¤ºè¯æ³¨å…¥ã€‚

        æ³¨æ„ï¼šæ­¤æ–‡æœ¬å¿…é¡»åœ¨æ•´ä¸ª turn å†…ä¿æŒç¨³å®šï¼ˆä¸å«åŠ¨æ€è®¡æ•°ç­‰ï¼‰ï¼Œ
        ä»¥ç¡®ä¿ç³»ç»Ÿæç¤ºå‰ç¼€ä¸€è‡´æ€§ï¼Œæœ€å¤§åŒ– provider prompt cache å‘½ä¸­ç‡ã€‚
        """
        e = self._engine
        if not e.workspace.transaction_enabled or e.transaction is None:
            return ""
        lines = [
            "## âš ï¸ å·¥ä½œåŒºäº‹åŠ¡æ¨¡å¼å·²å¯ç”¨",
            "æ‰€æœ‰æ–‡ä»¶è¯»å†™æ“ä½œå·²è‡ªåŠ¨é‡å®šå‘åˆ° `outputs/backups/` ä¸‹çš„å·¥ä½œå‰¯æœ¬ã€‚",
            "åŸå§‹æ–‡ä»¶ä¸ä¼šè¢«ä¿®æ”¹ã€‚æ“ä½œå®Œæˆåç”¨æˆ·å¯é€šè¿‡ `/backup apply` å°†ä¿®æ”¹åº”ç”¨åˆ°åŸæ–‡ä»¶ã€‚",
        ]
        # ç»Ÿä¸€ç‰ˆæœ¬ç®¡ç†å™¨å¯ç”¨æ—¶ï¼Œè¿½åŠ ç‰ˆæœ¬è¿½è¸ªä¿¡æ¯
        fvm = getattr(e, "_fvm", None)
        if fvm is not None:
            tracked = fvm.list_all_tracked()
            if tracked:
                lines.append(f"å½“å‰æœ‰ {len(tracked)} ä¸ªæ–‡ä»¶å—ç‰ˆæœ¬è¿½è¸ªä¿æŠ¤ï¼Œæ”¯æŒç²¾ç¡®å›æ»šåˆ°åŸå§‹ç‰ˆæœ¬ã€‚")
        return "\n".join(lines)

    def _build_mcp_context_notice(self) -> str:
        """ç”Ÿæˆå·²è¿æ¥ MCP Server çš„æ¦‚è¦ä¿¡æ¯ï¼Œæ³¨å…¥ system promptã€‚"""
        e = self._engine
        servers = e._mcp_manager.get_server_info()
        if not servers:
            return ""
        lines = ["## MCP æ‰©å±•èƒ½åŠ›"]
        for srv in servers:
            name = srv["name"]
            tool_count = srv.get("tool_count", 0)
            tool_names = srv.get("tools", [])
            tools_str = "ã€".join(tool_names) if tool_names else "æ— "
            lines.append(f"- **{name}**ï¼ˆ{tool_count} ä¸ªå·¥å…·ï¼‰ï¼š{tools_str}")
        lines.append(
            "ä»¥ä¸Š MCP å·¥å…·å·²æ³¨å†Œï¼Œå·¥å…·åå¸¦ `mcp_{server}_` å‰ç¼€ï¼Œå¯ç›´æ¥è°ƒç”¨ã€‚"
            "å½“ç”¨æˆ·è¯¢é—®ä½ æœ‰å“ªäº› MCP æˆ–å¤–éƒ¨èƒ½åŠ›æ—¶ï¼Œæ®æ­¤å¦‚å®å›ç­”ã€‚"
        )
        return "\n".join(lines)

    def _build_cow_path_notice(self) -> str:
        """ç”Ÿæˆ CoW è·¯å¾„æ˜ å°„æ¸…å•ï¼Œæ³¨å…¥ system promptã€‚

        å½“ä¼šè¯ä¸­å­˜åœ¨å—ä¿æŠ¤æ–‡ä»¶çš„ CoW å‰¯æœ¬æ—¶ï¼Œæ¯è½®éƒ½å°†æ˜ å°„æ¸…å•æ³¨å…¥ç³»ç»Ÿæç¤ºè¯ï¼Œ
        ç¡®ä¿ agent å§‹ç»ˆçŸ¥é“åº”ä½¿ç”¨å‰¯æœ¬è·¯å¾„è€ŒéåŸå§‹è·¯å¾„ã€‚
        """
        e = self._engine
        registry = e.state.cow_path_registry
        if not registry:
            return ""
        lines = [
            "## âš ï¸ æ–‡ä»¶ä¿æŠ¤è·¯å¾„æ˜ å°„ï¼ˆCoWï¼‰",
            "ä»¥ä¸‹åŸå§‹æ–‡ä»¶å—ä¿æŠ¤ï¼Œå·²è‡ªåŠ¨å¤åˆ¶åˆ° outputs/ ç›®å½•ã€‚",
            "**ä½ å¿…é¡»ä½¿ç”¨å‰¯æœ¬è·¯å¾„è¿›è¡Œæ‰€æœ‰åç»­è¯»å–å’Œå†™å…¥æ“ä½œï¼Œä¸¥ç¦è®¿é—®åŸå§‹è·¯å¾„ã€‚**",
            "",
            "| åŸå§‹è·¯å¾„ï¼ˆç¦æ­¢è®¿é—®ï¼‰ | å‰¯æœ¬è·¯å¾„ï¼ˆè¯·ä½¿ç”¨ï¼‰ |",
            "|---|---|",
        ]
        for src, dst in registry.items():
            lines.append(f"| `{src}` | `{dst}` |")
        lines.append("")
        lines.append(
            "å¦‚æœä½ åœ¨å·¥å…·å‚æ•°ä¸­ä½¿ç”¨äº†åŸå§‹è·¯å¾„ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é‡å®šå‘åˆ°å‰¯æœ¬ï¼Œ"
            "ä½†è¯·ä¸»åŠ¨è®°ä½å¹¶ä½¿ç”¨å‰¯æœ¬è·¯å¾„ä»¥é¿å…æ··æ·†ã€‚"
        )
        return "\n".join(lines)

    def _build_workspace_manifest_notice(self) -> str:
        """æ‡’åŠ è½½æ„å»ºå·¥ä½œåŒº Manifest å¹¶ç”Ÿæˆ system prompt æ³¨å…¥æ–‡æœ¬ã€‚

        ä¼˜å…ˆä½¿ç”¨åå°é¢„çƒ­ï¼šè‹¥å°šæœªå®Œæˆåˆ™ä¸é˜»å¡å½“å‰è½®æ¬¡ï¼Œç›´æ¥ç»§ç»­å¯¹è¯ã€‚
        æ³¨å…¥æ–‡æœ¬æ ¹æ®æ–‡ä»¶æ•°é‡è‡ªåŠ¨é€‰æ‹©è¯¦ç»†åº¦ã€‚
        """
        e = self._engine
        if e.workspace_manifest is None:
            e.start_workspace_manifest_prewarm()
        if e.workspace_manifest is None:
            return ""
        return e.workspace_manifest.get_system_prompt_summary()

    def _build_window_perception_notice(self) -> str:
        """æ¸²æŸ“çª—å£æ„ŸçŸ¥ç³»ç»Ÿæ³¨å…¥æ–‡æœ¬ã€‚"""
        e = self._engine
        requested_mode = e._requested_window_return_mode()
        return e._window_perception.build_system_notice(
            mode=requested_mode,
            model_id=e.active_model,
        )
    def _build_tool_index_notice(
        self,
        *,
        compact: bool = False,
        max_tools_per_category: int = 8,
    ) -> str:
        """ç”Ÿæˆå·¥å…·åˆ†ç±»ç´¢å¼•ï¼Œæ³¨å…¥ system promptã€‚

        æ‰€æœ‰å·¥å…·å§‹ç»ˆæš´éœ²å®Œæ•´ schemaï¼Œç»Ÿä¸€æŒ‰ç±»åˆ«å±•ç¤ºã€‚
        """
        from excelmanus.tools.policy import TOOL_CATEGORIES, TOOL_SHORT_DESCRIPTIONS

        _CATEGORY_LABELS: dict[str, str] = {
            "data_read": "æ•°æ®è¯»å–",
            "sheet": "å·¥ä½œè¡¨æ“ä½œ",
            "file": "æ–‡ä»¶æ“ä½œ",
            "code": "ä»£ç æ‰§è¡Œ",
            "macro": "å£°æ˜å¼å¤åˆæ“ä½œ",
            "vision": "å›¾ç‰‡è§†è§‰",
        }

        limit = max(1, int(max_tools_per_category))
        registered = set(self._all_tool_names())
        category_lines: list[str] = []

        def _format_tool_list(tools: Sequence[str], *, with_desc: bool = False) -> str:
            visible = list(tools[:limit])
            hidden = max(0, len(tools) - len(visible))
            if not visible:
                return ""
            if with_desc:
                parts_list = []
                for t in visible:
                    desc = TOOL_SHORT_DESCRIPTIONS.get(t)
                    parts_list.append(f"{t}({desc})" if desc else t)
                text = ", ".join(parts_list)
            else:
                text = ", ".join(visible)
            if hidden > 0:
                text += f" (+{hidden})"
            return text

        for cat, tools in TOOL_CATEGORIES.items():
            label = _CATEGORY_LABELS.get(cat, cat)
            available = [t for t in tools if t in registered]
            if not available:
                continue
            code_suffix = " [éœ€ fullaccess]" if cat == "code" else ""
            line = _format_tool_list(available, with_desc=True)
            if line:
                category_lines.append(f"- {label}ï¼š{line}{code_suffix}")

        if not category_lines:
            return ""

        parts: list[str] = ["## å·¥å…·ç´¢å¼•"]
        parts.append("å¯ç”¨å·¥å…·ï¼ˆæ‰€æœ‰å·¥å…·å‚æ•°å·²å®Œæ•´å¯è§ï¼Œç›´æ¥è°ƒç”¨ï¼‰ï¼š")
        parts.extend(category_lines)
        parts.append(
            "\nâš ï¸ å†™å…¥ç±»ä»»åŠ¡ï¼ˆå…¬å¼ã€æ•°æ®ã€æ ¼å¼ï¼‰å¿…é¡»è°ƒç”¨å·¥å…·æ‰§è¡Œï¼Œ"
            "ä¸å¾—ä»¥æ–‡æœ¬å»ºè®®æ›¿ä»£å®é™…å†™å…¥æ“ä½œã€‚"
        )
        return "\n".join(parts)



    def _set_window_perception_turn_hints(
        self,
        *,
        user_message: str,
        is_new_task: bool,
        task_tags: tuple[str, ...] | None = None,
    ) -> None:
        """è®¾ç½®çª—å£æ„ŸçŸ¥å±‚çš„å½“å‰è½®æç¤ºã€‚"""
        e = self._engine
        clipped_hint = self._clip_window_hint(user_message)
        e._window_perception.set_turn_hints(
            is_new_task=is_new_task,
            user_intent_summary=clipped_hint,
            agent_recent_output=self._clip_window_hint(self._latest_assistant_text()),
            turn_intent_hint=clipped_hint,
            task_tags=task_tags,
        )

    def _latest_assistant_text(self) -> str:
        """æå–æœ€è¿‘ä¸€æ¡ assistant æ–‡æœ¬ã€‚"""
        e = self._engine
        for item in reversed(e.memory.get_messages()):
            if str(item.get("role", "")).strip() != "assistant":
                continue
            from excelmanus.engine import _message_content_to_text
            text = _message_content_to_text(item.get("content"))
            if text.strip():
                return text.strip()
        return ""

    @staticmethod
    def _clip_window_hint(text: str, *, max_chars: int = 200) -> str:
        normalized = " ".join(str(text or "").split())
        if len(normalized) <= max_chars:
            return normalized
        return normalized[:max_chars]

