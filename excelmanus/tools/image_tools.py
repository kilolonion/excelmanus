"""å›¾ç‰‡å·¥å…·æ¨¡å—ï¼šread_image + æµæ°´çº¿å·¥å…·ï¼ˆrebuild / verifyï¼‰ã€‚"""

from __future__ import annotations

import base64
import json
from pathlib import Path
from typing import Any

from excelmanus.security import FileAccessGuard, SecurityViolationError
from excelmanus.tools._guard_ctx import get_guard as _get_ctx_guard
from excelmanus.tools.registry import ToolDef

_guard: FileAccessGuard | None = None
_SUPPORTED_EXTENSIONS = {".png", ".jpg", ".jpeg", ".gif", ".bmp", ".webp"}
_MAX_SIZE_BYTES = 20_000_000


def _get_guard() -> FileAccessGuard:
    """è·å–æˆ–åˆ›å»º FileAccessGuardï¼ˆä¼˜å…ˆ per-session contextvarï¼‰ã€‚"""
    ctx_guard = _get_ctx_guard()
    if ctx_guard is not None:
        return ctx_guard
    global _guard
    if _guard is None:
        _guard = FileAccessGuard(".")
    return _guard


def init_guard(workspace_root: str) -> None:
    global _guard
    _guard = FileAccessGuard(workspace_root)


def _resolve_path(user_path: str) -> Path:
    """è§£æè·¯å¾„ï¼›ä»…åœ¨æ˜¾å¼åˆå§‹åŒ– guard åæ‰§è¡Œå·¥ä½œåŒºæ ¡éªŒã€‚"""
    if _guard is None:
        return Path(user_path)
    return _get_guard().resolve_and_validate(user_path)


def read_image(*, file_path: str, detail: str = "auto") -> str:
    """è¯»å–æœ¬åœ°å›¾ç‰‡æ–‡ä»¶å¹¶è¿”å›å…ƒæ•°æ® + base64 æ³¨å…¥æ ‡è®°ã€‚"""
    try:
        path = _resolve_path(file_path)
    except SecurityViolationError as exc:
        return json.dumps(
            {"status": "error", "message": f"è·¯å¾„æ ¡éªŒå¤±è´¥: {exc}"},
            ensure_ascii=False,
        )
    if not path.is_file():
        return json.dumps(
            {"status": "error", "message": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"},
            ensure_ascii=False,
        )
    if path.suffix.lower() not in _SUPPORTED_EXTENSIONS:
        return json.dumps(
            {"status": "error", "message": f"ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼: {path.suffix}"},
            ensure_ascii=False,
        )
    size = path.stat().st_size
    if size > _MAX_SIZE_BYTES:
        return json.dumps(
            {
                "status": "error",
                "message": f"æ–‡ä»¶å¤§å°è¶…é™: {size} bytes > {_MAX_SIZE_BYTES}",
            },
            ensure_ascii=False,
        )

    raw = path.read_bytes()
    b64 = base64.b64encode(raw).decode("ascii")
    ext = path.suffix.lower()
    mime_map = {
        ".png": "image/png",
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".gif": "image/gif",
        ".bmp": "image/bmp",
        ".webp": "image/webp",
    }
    mime = mime_map.get(ext, "image/png")

    return json.dumps(
        {
            "status": "ok",
            "mime_type": mime,
            "size_bytes": size,
            "file_path": str(path),
            "hint": "å›¾ç‰‡å·²åŠ è½½åˆ°è§†è§‰ä¸Šä¸‹æ–‡ï¼Œä½ ç°åœ¨å¯ä»¥çœ‹åˆ°è¿™å¼ å›¾ç‰‡ã€‚",
            "__tool_result_image__": {
                "base64": b64,
                "mime_type": mime,
                "detail": detail,
            },
        },
        ensure_ascii=False,
    )


def _infer_number_format(display_text: str) -> str | None:
    """ä» display_text æ¨æ–­ Excel number_formatã€‚

    ç¤ºä¾‹:
        "12.50"    â†’ "#,##0.00"
        "85%"      â†’ "0%"
        "12.5%"    â†’ "0.0%"
        "$1,200"   â†’ "$#,##0"
        "Â¥1,200.00" â†’ "Â¥#,##0.00"
        "1,200"    â†’ "#,##0"
    """
    import re as _re

    text = display_text.strip()
    if not text:
        return None

    # ç™¾åˆ†æ•°
    pct_match = _re.match(r'^-?[\d,]+(\.\d+)?%$', text)
    if pct_match:
        decimals = len(pct_match.group(1)[1:]) if pct_match.group(1) else 0
        return f"0.{'0' * decimals}%" if decimals else "0%"

    # è´§å¸å‰ç¼€
    currency_prefix = ""
    for sym in ("$", "Â¥", "â‚¬", "Â£", "â‚©"):
        if text.startswith(sym):
            currency_prefix = sym
            text = text[len(sym):].strip()
            break
        # ä¹Ÿå¤„ç†å°¾ç¼€ï¼ˆå¦‚ "1,200 å…ƒ"ï¼‰â€” æš‚ä¸å¤„ç†

    # è´Ÿå·
    text = text.lstrip("-").strip()

    # åƒåˆ†ä½ + å°æ•°
    num_match = _re.match(r'^[\d,]+(\.\d+)?$', text)
    if num_match:
        has_comma = "," in text
        decimal_part = num_match.group(1)
        decimals = len(decimal_part[1:]) if decimal_part else 0

        if has_comma and decimals > 0:
            fmt = f"#,##0.{'0' * decimals}"
        elif has_comma:
            fmt = "#,##0"
        elif decimals > 0:
            fmt = f"0.{'0' * decimals}"
        else:
            return None  # çº¯æ•´æ•°ä¸éœ€è¦ç‰¹æ®Šæ ¼å¼

        return f"{currency_prefix}{fmt}" if currency_prefix else fmt

    # ä»…è´§å¸å‰ç¼€ + çº¯æ•°å­—ï¼ˆæ— åƒåˆ†ä½ï¼‰
    if currency_prefix:
        return f"{currency_prefix}#,##0"

    return None


def rebuild_excel_from_spec(*, spec_path: str, output_path: str = "outputs/draft.xlsx") -> str:
    """ä» ReplicaSpec JSON ç¡®å®šæ€§ç¼–è¯‘ä¸º Excel æ–‡ä»¶ã€‚"""
    from datetime import datetime

    from openpyxl import Workbook
    from openpyxl.styles import Alignment, Border, Font, PatternFill, Side
    from openpyxl.utils import get_column_letter

    from excelmanus.replica_spec import ReplicaSpec

    try:
        spec_file = _resolve_path(spec_path)
    except SecurityViolationError as exc:
        return json.dumps({"status": "error", "message": f"è·¯å¾„æ ¡éªŒå¤±è´¥: {exc}"}, ensure_ascii=False)

    if not spec_file.is_file():
        return json.dumps({"status": "error", "message": f"Spec æ–‡ä»¶ä¸å­˜åœ¨: {spec_path}"}, ensure_ascii=False)

    try:
        spec = ReplicaSpec.model_validate_json(spec_file.read_text(encoding="utf-8"))
    except Exception as exc:
        return json.dumps({"status": "error", "message": f"Spec è§£æå¤±è´¥: {exc}"}, ensure_ascii=False)

    wb = Workbook()
    # åˆ é™¤é»˜è®¤ sheet
    if wb.sheetnames:
        del wb[wb.sheetnames[0]]

    # åº”ç”¨ WorkbookSpec å…¨å±€é»˜è®¤å­—ä½“ï¼ˆæ›¿æ¢ openpyxl å†…ç½®çš„ Calibri 11ptï¼‰
    if spec.workbook and spec.workbook.default_font:
        df = spec.workbook.default_font
        wb._fonts[0] = Font(
            name=df.name or "Calibri",
            size=df.size or 11,
            bold=df.bold or False,
            italic=df.italic or False,
            color=df.color.lstrip("#") if df.color else None,
        )

    cells_written = 0
    styles_applied = 0
    merges_applied = 0
    formulas_written = 0
    skipped_items: list[str] = []

    for sheet_spec in spec.sheets:
        ws = wb.create_sheet(title=sheet_spec.name)

        # æ„å»º openpyxl æ ·å¼å¯¹è±¡ç¼“å­˜
        style_cache: dict[str, dict[str, Any]] = {}
        for style_id, style_class in sheet_spec.styles.items():
            s: dict[str, Any] = {}
            if style_class.font:
                f = style_class.font
                s["font"] = Font(
                    name=f.name,
                    size=f.size,
                    bold=f.bold,
                    italic=f.italic,
                    color=f.color.lstrip("#") if f.color else None,
                )
            if style_class.fill and style_class.fill.color:
                s["fill"] = PatternFill(
                    patternType="solid",
                    fgColor=style_class.fill.color.lstrip("#"),
                )
            if style_class.border:
                b = style_class.border
                # ä¼˜å…ˆä½¿ç”¨å››è¾¹ç‹¬ç«‹æ ·å¼ï¼Œå›é€€åˆ°ç»Ÿä¸€æ ·å¼
                def _make_side(side_spec, fallback_style=None, fallback_color=None):
                    st = side_spec.style if side_spec else fallback_style
                    cl = side_spec.color if side_spec else fallback_color
                    if not st:
                        return Side()
                    return Side(
                        style=st,
                        color=cl.lstrip("#") if cl else None,
                    )
                if b.top or b.bottom or b.left or b.right:
                    # å››è¾¹ç‹¬ç«‹æ¨¡å¼
                    s["border"] = Border(
                        top=_make_side(b.top, b.style, b.color),
                        bottom=_make_side(b.bottom, b.style, b.color),
                        left=_make_side(b.left, b.style, b.color),
                        right=_make_side(b.right, b.style, b.color),
                    )
                elif b.style:
                    # ç»Ÿä¸€æ ·å¼ï¼ˆå‘åå…¼å®¹ï¼‰
                    side = Side(
                        style=b.style,
                        color=b.color.lstrip("#") if b.color else None,
                    )
                    s["border"] = Border(left=side, right=side, top=side, bottom=side)
            if style_class.alignment:
                a = style_class.alignment
                s["alignment"] = Alignment(
                    horizontal=a.horizontal,
                    vertical=a.vertical,
                    wrap_text=a.wrap_text,
                )
            style_cache[style_id] = s

        # å†™å…¥ cells
        for cell_spec in sheet_spec.cells:
            cell = ws[cell_spec.address]
            # å€¼ç±»å‹è½¬æ¢
            if cell_spec.value_type == "formula" and cell_spec.value and str(cell_spec.value).startswith("="):
                cell.value = str(cell_spec.value)
                formulas_written += 1
            elif cell_spec.formula_candidate and cell_spec.confidence >= 0.8:
                cell.value = cell_spec.formula_candidate
                formulas_written += 1
            elif cell_spec.value_type == "number" and cell_spec.value is not None:
                try:
                    cell.value = float(cell_spec.value) if "." in str(cell_spec.value) else int(cell_spec.value)
                except (ValueError, TypeError):
                    cell.value = cell_spec.value
            elif cell_spec.value_type == "boolean" and cell_spec.value is not None:
                cell.value = bool(cell_spec.value)
            elif cell_spec.value_type == "date" and cell_spec.value is not None:
                try:
                    cell.value = datetime.fromisoformat(str(cell_spec.value))
                except (ValueError, TypeError):
                    cell.value = cell_spec.value
            elif cell_spec.value_type == "empty":
                cell.value = None
            else:
                cell.value = cell_spec.value

            # number_formatï¼šä¼˜å…ˆä½¿ç”¨æ˜¾å¼æŒ‡å®šï¼Œå¦åˆ™ä» display_text æ¨æ–­
            if cell_spec.number_format:
                cell.number_format = cell_spec.number_format
            elif cell_spec.display_text and cell_spec.value_type == "number" and cell_spec.value is not None:
                inferred_fmt = _infer_number_format(cell_spec.display_text)
                if inferred_fmt:
                    cell.number_format = inferred_fmt

            # åº”ç”¨æ ·å¼
            if cell_spec.style_id and cell_spec.style_id in style_cache:
                s = style_cache[cell_spec.style_id]
                if "font" in s:
                    cell.font = s["font"]
                if "fill" in s:
                    cell.fill = s["fill"]
                if "border" in s:
                    cell.border = s["border"]
                if "alignment" in s:
                    cell.alignment = s["alignment"]
                styles_applied += 1

            cells_written += 1

        # åˆå¹¶å•å…ƒæ ¼ï¼ˆå®‰å…¨æ¨¡å¼ï¼šæ£€æµ‹éé”šç‚¹ä½ç½®çš„æ•°æ®å†²çªï¼‰
        # æ„å»º spec ä¸­æœ‰å€¼çš„ cell åœ°å€é›†åˆ
        from openpyxl.utils import range_boundaries

        valued_cells: dict[str, str] = {}  # åœ°å€ â†’ å€¼çš„ repr
        for cs in sheet_spec.cells:
            if cs.value is not None and cs.value_type != "empty":
                valued_cells[cs.address.upper()] = repr(cs.value)

        for mr in sheet_spec.merged_ranges:
            try:
                min_col, min_row, max_col, max_row = range_boundaries(mr.range)
                anchor = f"{get_column_letter(min_col)}{min_row}"
                # æ£€æµ‹éé”šç‚¹ä½ç½®æ˜¯å¦æœ‰ spec å®šä¹‰çš„å€¼
                conflict_cells: list[str] = []
                for r in range(min_row, max_row + 1):
                    for c in range(min_col, max_col + 1):
                        addr = f"{get_column_letter(c)}{r}"
                        if addr.upper() != anchor.upper() and addr.upper() in valued_cells:
                            conflict_cells.append(addr)
                if conflict_cells:
                    skipped_items.append(
                        f"merge {mr.range} è·³è¿‡: éé”šç‚¹å•å…ƒæ ¼ {', '.join(conflict_cells)} "
                        f"å«æœ‰å€¼ï¼Œåˆå¹¶ä¼šå¯¼è‡´æ•°æ®ä¸¢å¤±"
                    )
                    continue
                ws.merge_cells(mr.range)
                merges_applied += 1
            except Exception as exc:
                skipped_items.append(f"merge {mr.range}: {exc}")

        # åˆ—å®½ï¼ˆå®¹é”™å¤„ç†ï¼šæ•°ç»„é•¿åº¦ä¸å®é™…åˆ—æ•°ä¸åŒ¹é…æ—¶åšæˆªæ–­/å¿½ç•¥ï¼‰
        max_col_used = ws.max_column or 1
        for i, width in enumerate(sheet_spec.column_widths):
            if i >= max_col_used + 10:  # å…è®¸å°‘é‡æº¢å‡ºï¼Œè¶…è¿‡å¤ªå¤šæˆªæ–­
                break
            try:
                col_letter = get_column_letter(i + 1)
                if isinstance(width, (int, float)) and width > 0:
                    ws.column_dimensions[col_letter].width = width
            except (ValueError, TypeError):
                skipped_items.append(f"column_width[{i}]: æ— æ•ˆå€¼ {width!r}")

        # è¡Œé«˜
        for row_str, height in sheet_spec.row_heights.items():
            try:
                ws.row_dimensions[int(row_str)].height = height
            except (ValueError, TypeError):
                pass

        # å†»ç»“çª—æ ¼
        if sheet_spec.freeze_panes:
            ws.freeze_panes = sheet_spec.freeze_panes

    # ä¿å­˜
    try:
        out = _resolve_path(output_path)
    except SecurityViolationError as exc:
        return json.dumps({"status": "error", "message": f"è·¯å¾„æ ¡éªŒå¤±è´¥: {exc}"}, ensure_ascii=False)
    out.parent.mkdir(parents=True, exist_ok=True)
    wb.save(str(out))

    return json.dumps({
        "status": "ok",
        "output_path": str(out),
        "build_summary": {
            "cells_written": cells_written,
            "styles_applied": styles_applied,
            "merges_applied": merges_applied,
            "formulas_written": formulas_written,
            "skipped_items": skipped_items,
        },
    }, ensure_ascii=False)


def verify_excel_replica(
    *, spec_path: str, excel_path: str, report_path: str = "outputs/replica_diff_report.md",
) -> str:
    """éªŒè¯ Excel æ–‡ä»¶ä¸ ReplicaSpec çš„ä¸€è‡´æ€§ï¼Œç”Ÿæˆå·®å¼‚æŠ¥å‘Šã€‚"""
    from openpyxl import load_workbook

    from excelmanus.replica_spec import ReplicaSpec

    try:
        spec_file = _resolve_path(spec_path)
        excel_file = _resolve_path(excel_path)
        rp = _resolve_path(report_path)
    except SecurityViolationError as exc:
        return json.dumps({"status": "error", "message": f"è·¯å¾„æ ¡éªŒå¤±è´¥: {exc}"}, ensure_ascii=False)

    if not spec_file.is_file():
        return json.dumps({"status": "error", "message": f"Spec æ–‡ä»¶ä¸å­˜åœ¨: {spec_path}"}, ensure_ascii=False)
    if not excel_file.is_file():
        return json.dumps({"status": "error", "message": f"Excel æ–‡ä»¶ä¸å­˜åœ¨: {excel_path}"}, ensure_ascii=False)

    try:
        spec = ReplicaSpec.model_validate_json(spec_file.read_text(encoding="utf-8"))
    except Exception as exc:
        return json.dumps({"status": "error", "message": f"Spec è§£æå¤±è´¥: {exc}"}, ensure_ascii=False)

    try:
        wb = load_workbook(str(excel_file))
    except Exception as exc:
        return json.dumps({"status": "error", "message": f"Excel åŠ è½½å¤±è´¥: {exc}"}, ensure_ascii=False)

    matches = 0
    mismatches: list[str] = []
    merge_conflicts: list[str] = []
    missing: list[str] = []
    low_confidence: list[str] = []
    total_cells = 0

    for sheet_spec in spec.sheets:
        if sheet_spec.name not in wb.sheetnames:
            missing.append(f"Sheet '{sheet_spec.name}' ä¸å­˜åœ¨äº Excel ä¸­")
            continue
        ws = wb[sheet_spec.name]

        # æ„å»ºåˆå¹¶åŒºåŸŸæŸ¥æ‰¾è¡¨ï¼šaddr â†’ (anchor_addr, merge_range_str)
        merge_lookup: dict[str, tuple[str, str]] = {}
        from openpyxl.utils import get_column_letter
        for merged_range in ws.merged_cells.ranges:
            anchor_addr = f"{get_column_letter(merged_range.min_col)}{merged_range.min_row}"
            for r in range(merged_range.min_row, merged_range.max_row + 1):
                for c in range(merged_range.min_col, merged_range.max_col + 1):
                    addr = f"{get_column_letter(c)}{r}"
                    if addr.upper() != anchor_addr.upper():
                        merge_lookup[addr.upper()] = (anchor_addr, str(merged_range))

        # å€¼æ¯”å¯¹
        for cell_spec in sheet_spec.cells:
            total_cells += 1
            try:
                actual = ws[cell_spec.address].value
            except Exception:
                missing.append(f"{sheet_spec.name}!{cell_spec.address}: æ— æ³•è¯»å–")
                continue

            expected = cell_spec.value
            # ç±»å‹æ„ŸçŸ¥æ¯”è¾ƒ
            if _values_match(expected, actual):
                matches += 1
            elif actual is None and cell_spec.address.upper() in merge_lookup:
                # è¯¥ cell åœ¨åˆå¹¶åŒºåŸŸçš„éé”šç‚¹ä½ç½®ï¼Œå€¼è¢«åˆå¹¶æ“ä½œæ¸…é›¶
                anchor, mr_str = merge_lookup[cell_spec.address.upper()]
                merge_conflicts.append(
                    f"{sheet_spec.name}!{cell_spec.address}: æœŸæœ›={expected!r} "
                    f"ä½†è¯¥å•å…ƒæ ¼åœ¨åˆå¹¶åŒºåŸŸ {mr_str} å†…ï¼ˆé”šç‚¹={anchor}ï¼‰ï¼Œå€¼è¢«åˆå¹¶è¦†ç›–"
                )
                # ä»è®¡ä¸ºåŒ¹é…ï¼ˆæ•°æ®åœ¨é”šç‚¹å¯è¯»ï¼Œè¿™æ˜¯ merge çš„é¢„æœŸè¡Œä¸ºï¼‰
                matches += 1
            else:
                mismatches.append(
                    f"{sheet_spec.name}!{cell_spec.address}: æœŸæœ›={expected!r} å®é™…={actual!r}"
                )

        # åˆå¹¶æ¯”å¯¹
        actual_merges = {str(m) for m in ws.merged_cells.ranges}
        for mr in sheet_spec.merged_ranges:
            if mr.range not in actual_merges:
                mismatches.append(f"{sheet_spec.name}: åˆå¹¶èŒƒå›´ {mr.range} ç¼ºå¤±")

    # æ”¶é›†ä½ç½®ä¿¡é¡¹
    for u in spec.uncertainties:
        low_confidence.append(f"{u.location}: {u.reason} (ç½®ä¿¡åº¦={u.confidence:.0%})")

    match_rate = matches / total_cells if total_cells > 0 else 1.0

    # ç”Ÿæˆ Markdown æŠ¥å‘Š
    report_lines = [
        "# ReplicaSpec éªŒè¯æŠ¥å‘Š\n",
        f"**åŒ¹é…ç‡**: {match_rate:.1%} ({matches}/{total_cells})\n",
    ]
    if not mismatches and not missing and not merge_conflicts:
        report_lines.append("## âœ… å…¨éƒ¨åŒ¹é…\n")
    if mismatches:
        report_lines.append(f"## âŒ ä¸åŒ¹é…é¡¹ ({len(mismatches)})\n")
        for m in mismatches:
            report_lines.append(f"- {m}")
        report_lines.append("")
    if merge_conflicts:
        report_lines.append(f"## ğŸ”€ åˆå¹¶å•å…ƒæ ¼å†²çª ({len(merge_conflicts)})\n")
        report_lines.append("ä»¥ä¸‹å•å…ƒæ ¼åœ¨åˆå¹¶åŒºåŸŸéé”šç‚¹ä½ç½®ï¼Œå€¼å·²è¢«åˆå¹¶è¦†ç›–ï¼ˆä¸å½±å“åŒ¹é…ç‡ï¼‰ï¼š\n")
        for mc in merge_conflicts:
            report_lines.append(f"- {mc}")
        report_lines.append("")
    if missing:
        report_lines.append(f"## âš ï¸ ç¼ºå¤±é¡¹ ({len(missing)})\n")
        for m in missing:
            report_lines.append(f"- {m}")
        report_lines.append("")
    if low_confidence:
        report_lines.append(f"## ğŸ” ä½ç½®ä¿¡é¡¹ ({len(low_confidence)})\n")
        report_lines.append("ä»¥ä¸‹é¡¹ç›®å»ºè®®äººå·¥ç¡®è®¤ï¼š\n")
        for lc in low_confidence:
            report_lines.append(f"- {lc}")
        report_lines.append("")

    report_text = "\n".join(report_lines)
    rp.parent.mkdir(parents=True, exist_ok=True)
    rp.write_text(report_text, encoding="utf-8")

    return json.dumps({
        "status": "ok",
        "report_path": str(rp),
        "match_rate": round(match_rate, 4),
        "issues": {
            "missing": len(missing),
            "conflict": len(mismatches),
            "merge_conflicts": len(merge_conflicts),
            "low_confidence": len(low_confidence),
            "total": len(missing) + len(mismatches) + len(low_confidence),
        },
    }, ensure_ascii=False)


def _values_match(expected: Any, actual: Any) -> bool:
    """ç±»å‹æ„ŸçŸ¥çš„å€¼æ¯”è¾ƒã€‚"""
    if expected is None and actual is None:
        return True
    if expected is None or actual is None:
        return False
    # æ•°å€¼æ¯”è¾ƒï¼ˆint/float äº’é€šï¼‰
    try:
        if isinstance(expected, (int, float)) or isinstance(actual, (int, float)):
            return abs(float(expected) - float(actual)) < 1e-9
    except (ValueError, TypeError):
        pass
    # æ—¥æœŸå½’ä¸€åŒ–æ¯”è¾ƒ
    d_expected = _normalize_to_date(expected)
    d_actual = _normalize_to_date(actual)
    if d_expected is not None and d_actual is not None:
        return d_expected == d_actual
    return str(expected) == str(actual)

def _normalize_to_date(val: Any) -> "date | None":
    """å°è¯•å°†å€¼å½’ä¸€åŒ–ä¸º date å¯¹è±¡ã€‚"""
    from datetime import date, datetime

    if isinstance(val, datetime):
        return val.date()
    if isinstance(val, date):
        return val
    if isinstance(val, str):
        for fmt in ("%Y-%m-%d", "%Y/%m/%d"):
            try:
                return datetime.strptime(val.strip(), fmt).date()
            except ValueError:
                continue
    return None



def get_tools() -> list[ToolDef]:
    return [
        ToolDef(
            name="read_image",
            description="è¯»å–æœ¬åœ°å›¾ç‰‡æ–‡ä»¶å¹¶åŠ è½½åˆ°è§†è§‰ä¸Šä¸‹æ–‡ï¼ˆpng/jpg/gif/bmp/webpï¼‰",
            input_schema={
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "å›¾ç‰‡æ–‡ä»¶çš„ç»å¯¹æˆ–ç›¸å¯¹è·¯å¾„",
                    },
                    "detail": {
                        "type": "string",
                        "enum": ["auto", "low", "high"],
                        "default": "auto",
                        "description": "å›¾ç‰‡åˆ†æç²¾åº¦",
                    },
                },
                "required": ["file_path"],
                "additionalProperties": False,
            },
            func=read_image,
            max_result_chars=2000,  # æ³¨å…¥å base64 å·²ç§»é™¤ï¼Œä»…å‰©å…ƒæ•°æ®
            write_effect="none",
        ),
        ToolDef(
            name="rebuild_excel_from_spec",
            description="ä» ReplicaSpec JSON ç¼–è¯‘ä¸º Excel æ–‡ä»¶",
            input_schema={
                "type": "object",
                "properties": {
                    "spec_path": {
                        "type": "string",
                        "description": "ReplicaSpec JSON æ–‡ä»¶è·¯å¾„",
                    },
                    "output_path": {
                        "type": "string",
                        "description": "è¾“å‡º Excel æ–‡ä»¶è·¯å¾„",
                        "default": "outputs/draft.xlsx",
                    },
                },
                "required": ["spec_path"],
                "additionalProperties": False,
            },
            func=rebuild_excel_from_spec,
            write_effect="workspace_write",
        ),
        ToolDef(
            name="verify_excel_replica",
            description="éªŒè¯ Excel æ–‡ä»¶ä¸ ReplicaSpec çš„ä¸€è‡´æ€§ï¼Œç”Ÿæˆå·®å¼‚æŠ¥å‘Š",
            input_schema={
                "type": "object",
                "properties": {
                    "spec_path": {
                        "type": "string",
                        "description": "ReplicaSpec JSON æ–‡ä»¶è·¯å¾„",
                    },
                    "excel_path": {
                        "type": "string",
                        "description": "è¦éªŒè¯çš„ Excel æ–‡ä»¶è·¯å¾„",
                    },
                    "report_path": {
                        "type": "string",
                        "description": "å·®å¼‚æŠ¥å‘Šè¾“å‡ºè·¯å¾„",
                        "default": "outputs/replica_diff_report.md",
                    },
                },
                "required": ["spec_path", "excel_path"],
                "additionalProperties": False,
            },
            func=verify_excel_replica,
            write_effect="workspace_write",
        ),
        ToolDef(
            name="extract_table_spec",
            description=(
                "ä»å›¾ç‰‡è‡ªåŠ¨æå–è¡¨æ ¼ç»“æ„å’Œæ ·å¼ï¼Œç”Ÿæˆ ReplicaSpec JSONã€‚"
                "æ”¯æŒå¤šè¡¨æ ¼æ£€æµ‹ï¼Œé‡‡ç”¨æ¸è¿›å¼ 4 é˜¶æ®µæå–ã€‚"
            ),
            input_schema={
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "å›¾ç‰‡æ–‡ä»¶è·¯å¾„",
                    },
                    "output_path": {
                        "type": "string",
                        "description": "è¾“å‡º ReplicaSpec JSON è·¯å¾„",
                        "default": "outputs/replica_spec.json",
                    },
                    "skip_style": {
                        "type": "boolean",
                        "description": "è·³è¿‡æ ·å¼æå–ï¼ˆä»…æå–æ•°æ®ç»“æ„ï¼Œé€Ÿåº¦æ›´å¿«ï¼‰",
                        "default": False,
                    },
                    "resume_from_spec": {
                        "type": "string",
                        "description": "æ–­ç‚¹ç»­è·‘ï¼šä¼ å…¥ä¸­é—´ spec æ–‡ä»¶è·¯å¾„ï¼Œä»è¯¥é˜¶æ®µä¹‹åç»§ç»­",
                    },
                },
                "required": ["file_path"],
                "additionalProperties": False,
            },
            func=lambda **kw: json.dumps({"__extract_pending__": True}),
            write_effect="workspace_write",
            max_result_chars=5000,
        ),
    ]
