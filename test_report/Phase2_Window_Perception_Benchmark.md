# 窗口感知 Phase 2 完整基准测试报告

> **测试日期**：2026-02-15
> **测试范围**：窗口感知功能在不同主模型、不同 Advisor 配置下的性能对比
> **测试工具**：`excelmanus.bench`（串行模式，concurrency=1）

---

## 一、测试背景

### 1.1 功能简介

**窗口感知（Window Perception）** 为 Agent 构建类人的空间感知框架，模拟人类操作 Excel 时的"视觉体验"。核心包含三层架构：

| 层级 | 名称 | 说明 |
|------|------|------|
| 第一层 | 静态感知 | 桌面/目录视图，Agent "睁眼可见" |
| 第二层 | 实时感知 | 工具返回值增强，程序化推断窗口状态 |
| 第三层 | 反思感知 | 小模型 Advisor 异步优化窗口生命周期 |

窗口生命周期借鉴 iOS App Lifecycle，分四级状态：
- **ACTIVE**（前台）→ **BACKGROUND**（最近缩略图）→ **SUSPENDED**（图标）→ **TERMINATED**（回收）

### 1.2 测试配置

三种窗口感知模式：

| 配置 | WP 开关 | Advisor 模式 | 说明 |
|------|---------|-------------|------|
| **OFF** | 关闭 | N/A | 基线，无窗口感知 |
| **RULES** | 开启 | rules | 纯规则降级（基于 idle_turns） |
| **HYBRID** | 开启 | hybrid | 小模型 + 规则混合决策 |

### 1.3 测试套件

| 套件 | 用例数 | 轮次 | 说明 |
|------|--------|------|------|
| 01_基础读取类 | 3 | 单轮 | 读取、统计、筛选 |
| 02_数据分析类 | 4 | 单轮 | 聚合、折扣率、工资统计 |
| 06_跨表操作类 | 3 | 单轮 | 跨表写入、日薪计算 |
| 15_多轮对话 | 4 | 2-3 轮 | 先读后分析、探查后写入 |
| 窗口感知_多轮复杂场景 | 3 | 3 轮 | 跨 sheet 探查、多表切换 |
| **窗口感知_超复杂场景** | **4** | **6-7 轮** | 全表审计、跨表关联分析、数据写入 |

共 **6 个套件 × 21 个用例**。

---

## 二、GPT-5.3-codex 主模型测试（Phase 2v3）

### 2.1 测试条件

- **主模型**：`gpt-5.3-codex`（via `right.codes/codex/v1`）
- **辅助模型（flash）**：`gemini-3-flash-preview`（via `right.codes/gemini/v1beta`）
- **辅助模型（pro）**：`gemini-3-pro-preview`（同上）
- **执行方式**：四组串行（OFF / RULES / HYBRID-flash / HYBRID-pro）

### 2.2 全局汇总

| 指标 | OFF | RULES | HYBRID(flash) | HYBRID(pro) |
|------|-----|-------|---------------|-------------|
| 通过率 | 21/21 (100%) | 21/21 (100%) | 21/21 (100%) | 21/21 (100%) |
| **总 Tokens** | **370,079** | **440,100** | **313,464** ⭐ | **360,120** |
| 总耗时 | 225.8s | 242.8s | 224.1s ⭐ | 231.1s |
| 工具失败 | 0 | 0 | 0 | 0 |

### 2.3 Token 节省率（vs OFF 基线）

| 配置 | Token 变化 | 节省率 |
|------|-----------|--------|
| RULES | +70,021 | **+18.9%**（膨胀） |
| HYBRID(flash) | -56,615 | **-15.3%**（节省） |
| HYBRID(pro) | -9,959 | **-2.7%**（轻微节省） |

### 2.4 分场景详细对比

#### 单轮简单场景（基础读取 + 数据分析 + 跨表操作，10 用例）

| 指标 | OFF | RULES | HYBRID(flash) | HYBRID(pro) |
|------|-----|-------|---------------|-------------|
| Tokens | 86,980 | 87,076 | 87,071 | 96,325 |
| LLM 调用 | 10 | 10 | 10 | 11 |
| 耗时 | 45.8s | 42.9s | 63.6s | 51.5s |

> **结论**：单轮场景四组无显著差异，Token 偏差 < 3%。窗口感知对简单场景**零副作用**。

#### 多轮对话（4 用例，2-3 轮）

| 指标 | OFF | RULES | HYBRID(flash) | HYBRID(pro) |
|------|-----|-------|---------------|-------------|
| **Tokens** | **65,011** | **79,707** | **50,099** ⭐ | **54,725** |
| LLM 调用 | 10 | 11 | 7 ⭐ | 8 |
| 迭代 | 10 | 11 | 7 ⭐ | 8 |

> **结论**：**多轮场景是 HYBRID 的核心优势区域**。
> - HYBRID(flash) Token 比 OFF **节省 22.9%**，LLM 调用减少 30%
> - HYBRID(pro) Token 比 OFF **节省 15.8%**
> - RULES 比 OFF **膨胀 22.6%**

#### 多轮复杂场景（3 用例，3 轮）

| 指标 | OFF | RULES | HYBRID(flash) | HYBRID(pro) |
|------|-----|-------|---------------|-------------|
| **Tokens** | **69,878** | **71,521** | **79,147** | **56,714** ⭐ |
| LLM 调用 | 11 | 11 | 12 | 9 ⭐ |

> **结论**：3 轮复杂场景中 **HYBRID(pro) 最优**，Token 节省 18.8%，迭代减少 18.2%。
> HYBRID(flash) 反而膨胀 13.3%。Pro 的推理能力在此场景更有效。

#### ⭐ 超复杂场景（4 用例，6-7 轮）— 本轮新增

| 指标 | OFF | RULES | HYBRID(flash) | HYBRID(pro) |
|------|-----|-------|---------------|-------------|
| **Tokens** | **148,210** | **201,796** | **97,147** ⭐ | **152,356** |
| LLM 调用 | 23 | 30 | 15 ⭐ | 23 |
| 迭代 | 23 | 30 | 15 ⭐ | 23 |
| 耗时 | 96.5s | 109.5s | 63.6s ⭐ | 106.5s |

> **结论**：**超复杂场景是最重要的发现**。
> - **HYBRID(flash) 全面碾压**：Token 节省 34.4%，LLM 调用减少 34.8%，耗时减少 34.1%
> - **RULES 严重膨胀**：Token 膨胀 36.1%，纯规则缺乏"预见性"
> - Flash 在超长链条中的优势：生命周期决策更快更果断，窗口降级更及时

### 2.5 Flash vs Pro 辅助模型对比

| 场景类型 | 推荐模型 | 原因 |
|----------|---------|------|
| 单轮简单 | 无差别 | WP 无显著影响 |
| 多轮（2-3 轮） | **flash** | 更快的生命周期决策，Token 更省 |
| 复杂多轮（3 轮） | **pro** | 更好的推理能力，窗口优化更精准 |
| 超复杂（6-7 轮） | **flash** | 果断降级策略在极端场景更优 |

**综合推荐**：`HYBRID(flash)` 作为默认生产配置。

---

## 三、DeepSeek-reasoner 主模型测试

### 3.1 测试条件

- **主模型**：`deepseek-reasoner`（via `api.deepseek.com/v1`）
- **辅助模型（HYBRID 组）**：`gemini-3-flash-preview`
- **Router/Planner**：`deepseek-chat`（非推理版，用于路由和子代理）
- **执行方式**：三组并行（OFF / RULES / HYBRID-flash），组内串行

### 3.2 已完成用例统计（测试仍在进行中）

| 指标 | DS OFF (14/21) | DS RULES (14/21) | DS HYBRID (10/21) | GPT OFF (21/21) |
|------|----------------|------------------|--------------------|-----------------|
| **总 Tokens** | **574,709** | **626,264** | **781,111** | 370,079 |
| 工具调用 | 37 | 38 | 37 | — |
| **工具失败** | **4** | **2** | **4** | **0** |
| LLM 调用 | 47 | 50 | 44 | — |
| **总耗时** | **697.2s** | **728.3s** | **738.1s** | 225.8s |

> ⚠️ **DeepSeek 14 个用例的 Token 已超过 GPT 21 个用例的全部总和。**

### 3.3 典型用例对比："产品销售额写入产品目录"

| 维度 | GPT-5.3-codex | DS-reasoner (OFF) | DS-reasoner (HYBRID) |
|------|--------------|-------------------|-----------------------|
| Tokens | **8,726** | **136,616** (15.7x) | **374,770** (42.9x) |
| 迭代 | 1 | 8 | 15 |
| 工具调用 | 0 | 8（含 1 失败） | 15（含 2 失败） |
| 耗时 | 4.4s | 99.9s (22.7x) | 296.9s (67.5x) |

**GPT 的行为**：利用路由注入的文件结构预览，一轮文本回复即完成。
**DS 的行为**：不信任预览数据 → 自己调工具验证 → Planner 子代理超时 → 逐步手动操作 → Coder 子代理也超时 → 最终用低级工具逐步完成。

### 3.4 DeepSeek 三大核心问题

#### 问题 1：Planner 子代理必定失败 🔴

```
计划生成失败：planner 执行失败：子代理达到最大迭代次数（4），已终止。
```

Planner 也使用 `deepseek-reasoner`，推理模型在生成结构化 Markdown 计划文档时效率极低，4 次迭代内无法完成。**每次浪费 16-21 秒。**

#### 问题 2：Coder 子代理超时 🔴

```
子代理执行失败（coder）：子代理达到最大迭代次数（6），已终止。
```

跨表写入类任务受影响最大。**每次浪费 47-65 秒。** 失败后 Agent 被迫用低级工具（`write_cells`、`filter_data`）逐步操作。

#### 问题 3：不信任路由预览，反复调工具验证 🟡

GPT-5.3 能直接从 system prompt 中注入的文件结构预览获取信息并一轮完成，而 DeepSeek **始终要自己调 `read_excel` 验证已有信息**，导致：
- 基础读取类用例：GPT 1 轮 0 工具调用 → DS 2 轮 1 次工具调用
- Token 翻倍（8.7K → 22K）

### 3.5 窗口感知对 DeepSeek 的影响

| 配置 | 已完成用例 Token | 评价 |
|------|----------------|------|
| DS OFF | 574K (14例) | 基线已极高 |
| DS RULES | 626K (14例) | +9.0%，与 GPT 趋势一致 |
| DS HYBRID | 781K (10例) | **反而更差**，flash advisor 频繁超时 |

**原因**：
- DS 每次 LLM 调用耗时 5-15s，远超 flash advisor 的 0.8s 超时限制
- Advisor 几乎每次都超时回退到规则模式
- 窗口感知注入的额外 context 在 DS 的高 Token 基础上进一步放大开销
- DS 的低效行为（多轮试探）完全抵消了窗口感知的优化收益

---

## 四、跨模型综合对比

### 4.1 Token 效率（归一化到每用例平均）

| 配置 | GPT-5.3 (21例) | DS-reasoner (14例) | DS/GPT 倍数 |
|------|----------------|-------------------|-------------|
| OFF | 17,623/例 | 41,051/例 | **2.33x** |
| RULES | 20,957/例 | 44,733/例 | **2.14x** |
| HYBRID(flash) | 14,927/例 | 78,111/例 | **5.23x** |

### 4.2 每秒处理效率

| 配置 | GPT tokens/s | DS tokens/s |
|------|-------------|-------------|
| OFF | 1,639 | 824 |
| RULES | 1,813 | 860 |
| HYBRID(flash) | 1,399 | 1,058 |

### 4.3 关键结论

| 维度 | GPT-5.3-codex | DeepSeek-reasoner |
|------|--------------|-------------------|
| **Agent 适配性** | ⭐⭐⭐⭐⭐ 极佳 | ⭐⭐ 差 |
| **单轮效率** | 高（常一轮完成） | 低（需 2+ 轮验证） |
| **子代理兼容性** | 完全正常 | Planner/Coder 全部超时 |
| **路由预览利用** | 直接采信 | 不信任，反复验证 |
| **窗口感知收益** | 显著（最高 -34.4%） | 负面（反而增加开销） |
| **推荐 WP 配置** | HYBRID(flash) | 不建议开启 |

---

## 五、结论与建议

### 5.1 窗口感知功能验证结果

| 阶段 | 验证结论 |
|------|---------|
| Phase 1 | 核心框架可行，简单场景无害，多轮场景初步有效 |
| Phase 1.5 | 生命周期管理解决了 Token 膨胀，复杂场景 Token -34.2% |
| **Phase 2** | **HYBRID(flash) 综合最优：总 Token -15.3%，超复杂场景 -34.4%** |

### 5.2 生产环境推荐配置

```env
# 主模型
EXCELMANUS_MODEL=gpt-5.3-codex

# 窗口感知
EXCELMANUS_WINDOW_PERCEPTION_ENABLED=true
EXCELMANUS_WINDOW_PERCEPTION_ADVISOR_MODE=hybrid

# 辅助模型（advisor + router）
EXCELMANUS_ROUTER_MODEL=gemini-3-flash-preview
```

---

## 四、Kimi K2.5 主模型测试（礼包站）

### 4.1 测试条件

- **主模型**：`moonshotai/kimi-k2.5`（via `api.umodelverse.ai/v1`，礼包站）
- **辅助模型（HYBRID 组）**：`gemini-3-flash-preview`（via `right.codes/gemini/v1beta`）
- **执行方式**：三组并行（OFF / RULES / HYBRID-flash），组内串行
- **完成度**：OFF 16/21，RULES 18/21，HYBRID 18/21（测试中断，以已完成部分分析）

### 4.2 已完成数据汇总

| 指标 | Kimi OFF (16例) | Kimi RULES (18例) | Kimi HYBRID (18例) | GPT OFF (21例) |
|------|-----------------|-------------------|--------------------|----------------|
| **总 Tokens** | **419,700** | **579,395** | **584,859** | 370,079 |
| 工具调用 | 28 | 35 | 36 | — |
| **工具失败** | **0** ✅ | **0** ✅ | **0** ✅ | **0** |
| LLM 调用 | 48 | 63 | 64 | — |
| 总耗时 | 679.4s | 725.0s | 679.8s | 225.8s |

### 4.3 分场景对比（Kimi vs GPT，可比套件）

#### 基础读取类（3 用例，单轮）

| 指标 | GPT OFF | GPT HYBRID(flash) | Kimi OFF | Kimi RULES | Kimi HYBRID |
|------|---------|-------------------|----------|------------|-------------|
| **Tokens** | **26,246** | **26,150** | **56,489** | **57,033** | **57,007** |
| LLM 调用 | 3 | 3 | 6 | 6 | 6 |
| 迭代 | 3 | 3 | 6 | 6 | 6 |

> **发现**：Kimi 在最简单的场景也需要 **2 轮迭代/用例**（先调工具读取 → 再回复），而 GPT 直接 1 轮完成。Token 翻倍（2.15x）。

#### 数据分析类（4 用例，单轮）

| 指标 | GPT OFF | GPT HYBRID(flash) | Kimi OFF | Kimi RULES | Kimi HYBRID |
|------|---------|-------------------|----------|------------|-------------|
| **Tokens** | **34,643** | **34,879** | **125,408** | **127,552** | **130,295** |
| LLM 调用 | 4 | 4 | 12 | 12 | 12 |
| 迭代 | 4 | 4 | 12 | 12 | 12 |

> **发现**：Kimi 每用例需要 **3 轮迭代**，Token 达 GPT 的 **3.6 倍**。尤其"环比增长最快月份"一个用例就消耗了 58-63K tokens（5 次迭代），GPT 仅需 9.7K。

#### 跨表操作类（3 用例，单轮）

| 指标 | GPT OFF | GPT HYBRID(flash) | Kimi OFF | Kimi RULES | Kimi HYBRID |
|------|---------|-------------------|----------|------------|-------------|
| Tokens | 26,091 | 26,042 | 26,505 | 26,479 | 26,504 |
| LLM 调用 | 3 | 3 | 3 | 3 | 3 |
| 迭代 | 3 | 3 | 3 | 3 | 3 |

> **发现**：跨表写入场景 Kimi 与 GPT 几乎一致（均 1 轮/用例），Token 偏差 < 2%。这类任务结构清晰，Kimi 能一次性生成计划。

#### 多轮对话（4 用例，2-3 轮）

| 指标 | GPT OFF | GPT HYBRID(flash) | Kimi OFF | Kimi RULES | Kimi HYBRID |
|------|---------|-------------------|----------|------------|-------------|
| **Tokens** | **65,011** | **50,099** ⭐ | **125,278** | **125,251** | **128,408** |
| LLM 调用 | 10 | 7 | 16 | 15 | 16 |
| 迭代 | 10 | 7 | 16 | 15 | 16 |

> **发现**：Kimi 多轮 Token 是 GPT 的 1.93x。更关键的是 **WP 对 Kimi 几乎无效** — 三组 Token 差异 < 2.5%。

#### 窗口感知_多轮复杂场景（3 用例，3 轮）

| 指标 | GPT OFF | GPT HYBRID(flash) | Kimi OFF (2/3) | Kimi RULES (3/3) | Kimi HYBRID (3/3) |
|------|---------|-------------------|----------------|-------------------|-------------------|
| **Tokens** | **69,878** | **79,147** | **86,020** (2例) | **133,790** | **129,823** |
| LLM 调用 | 11 | 12 | 11 (2例) | 16 | 16 |

> **发现**：Kimi 3 例 Token（130K+）接近 GPT 全部 21 例总和的 1/3。

#### 窗口感知_超复杂场景（4 用例，6-7 轮）

| 指标 | GPT OFF (4/4) | GPT HYBRID(flash) (4/4) | Kimi RULES (1/4) | Kimi HYBRID (1/4) |
|------|-------------|-------------------------|-------------------|-------------------|
| **Tokens** | **148,210** | **97,147** ⭐ | **109,290** (1例!) | **112,822** (1例!) |

> **发现**：Kimi 跑完 **1 个**超复杂用例的 Token（109-113K）就已接近 GPT 跑完 **全部 4 个**用例的 Token（97-148K）。极端场景下效率差距达 **4 倍以上**。

### 4.4 Kimi K2.5 核心问题分析

#### 问题 1：简单任务也必须多轮迭代 🟡

GPT 能从 system prompt 中注入的文件结构预览直接回答，Kimi 必须先调用 `read_excel` 读取数据再回复。导致：
- 基础读取类：2 轮/用例（GPT 1 轮），Token 2.15x
- 数据分析类：3 轮/用例（GPT 1 轮），Token 3.6x

#### 问题 2：复杂分析任务效率低 🟡

"环比增长最快月份"用例尤为典型：
- **GPT**：9.7K tokens，1 轮，直接规划
- **Kimi**：58-63K tokens，5 轮，逐步探索

Kimi 在需要多步推理的分析任务中效率显著低于 GPT。

#### 问题 3：窗口感知对 Kimi 无正面效果 🟡

三组（OFF / RULES / HYBRID）Token 差异极小（< 3%），说明：
- Kimi 不像 GPT 那样受益于窗口上下文缩减冗余信息
- Kimi 的行为模式固定（总是调工具 → 回复），不会利用窗口状态跳过工具调用
- Flash advisor 频繁超时（0.80s），无法有效优化生命周期

#### 优点：零工具失败 ✅

与 DeepSeek 不同，Kimi 的**子代理兼容性良好**：
- Planner / Coder 子代理未出现超时
- 跨表写入任务能一轮完成（与 GPT 一致）
- 三组共 52 例，0 次工具失败

### 4.5 Kimi vs DeepSeek vs GPT 三模型总结

| 维度 | GPT-5.3-codex | Kimi K2.5 | DeepSeek-reasoner |
|------|--------------|-----------|-------------------|
| **Agent 适配性** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐ |
| **单轮效率** | 极高（1 轮完成） | 中等（2-3 轮） | 低（2+ 轮 + 超时） |
| **子代理兼容** | ✅ 完全正常 | ✅ 正常 | ❌ 全部超时 |
| **工具失败率** | 0% | 0% | ~8% |
| **路由预览利用** | 直接采信 | 不信任，需验证 | 不信任，需验证 |
| **WP 收益** | 显著（-15%~-34%） | 无效（< 3%） | 负面（+增加开销） |
| **每例均 Token** | ~14.9K (HYBRID) | ~32.5K (HYBRID) | ~78.1K (HYBRID) |
| **推荐 WP 配置** | HYBRID(flash) | OFF（无收益） | OFF（有害） |

---

## 五、Claude Sonnet 4.5 主模型测试（礼包站）

### 5.1 测试条件

- **主模型**：`claude-sonnet-4-5-20250929`（via `api.umodelverse.ai/v1`，礼包站）
- **辅助模型（HYBRID 组）**：`gemini-3-flash-preview`（via `right.codes/gemini/v1beta`）
- **执行方式**：三组并行（OFF / RULES / HYBRID-flash），组内串行
- **完成度**：14/21 通过，7 例因**礼包站 402 额度不足**失败（非模型问题）
- **有效数据**：前 4 个套件（基础读取 + 数据分析 + 跨表操作 + 多轮对话，共 14 例）

### 5.2 有效数据汇总（14 例）

| 指标 | Sonnet OFF | Sonnet RULES | Sonnet HYBRID | GPT OFF (同14例) |
|------|-----------|-------------|---------------|-----------------|
| **总 Tokens** | **481,637** | **491,502** | **520,953** | ~222K (估) |
| 工具调用 | 23 | 23 | 25 | — |
| 工具失败 | 0 ✅ | 0 ✅ | 0 ✅ | 0 |
| LLM 调用 | 35 | 35 | 37 | — |
| 总耗时 | 226.7s | 225.2s | 222.1s | — |

### 5.3 分场景对比

#### 基础读取类（3 用例，单轮）

| 指标 | GPT OFF | GPT HYBRID | Sonnet OFF | Sonnet RULES | Sonnet HYBRID |
|------|---------|-----------|-----------|-------------|--------------|
| **Tokens** | **26,246** | **26,150** | **82,395** | **83,865** | **83,857** |
| LLM 调用 | 3 | 3 | 6 | 6 | 6 |
| 迭代 | 3 | 3 | 6 | 6 | 6 |

> **发现**：Sonnet 基础读取 Token 是 GPT 的 **3.14x**。与 Kimi 类似，Sonnet 每用例也需要 2 轮迭代。但 Sonnet 的 prompt token 更高（82K vs Kimi 57K），说明 Sonnet 的上下文窗口填充更大。

#### 数据分析类（4 用例，单轮）

| 指标 | GPT OFF | GPT HYBRID | Sonnet OFF | Sonnet RULES | Sonnet HYBRID |
|------|---------|-----------|-----------|-------------|--------------|
| **Tokens** | **34,643** | **34,879** | **129,135** | **130,588** | **130,576** |
| LLM 调用 | 4 | 4 | 9 | 9 | 9 |
| 迭代 | 4 | 4 | 9 | 9 | 9 |

> **发现**：Sonnet 数据分析 Token 是 GPT 的 **3.73x**。平均 2.25 轮/用例。"环比增长"用例 46.8K（GPT 9.7K），但仍优于 Kimi 的 58K。

#### 跨表操作类（3 用例，单轮）

| 指标 | GPT OFF | GPT HYBRID | Sonnet OFF | Sonnet RULES | Sonnet HYBRID |
|------|---------|-----------|-----------|-------------|--------------|
| **Tokens** | **26,091** | **26,042** | **56,472** | **57,825** | **114,572** |
| LLM 调用 | 3 | 3 | 4 | 4 | 6 |
| 迭代 | 3 | 3 | 4 | 4 | 6 |

> **发现**：跨表场景 Sonnet 需要比 GPT 多 1 轮迭代。**HYBRID 组出现 Token 翻倍**（114K vs OFF 56K），迭代从 4→6，表明窗口感知的额外上下文对 Sonnet 产生了负面干扰。

#### 多轮对话（4 用例，2-3 轮）

| 指标 | GPT OFF | GPT HYBRID | Sonnet OFF | Sonnet RULES | Sonnet HYBRID |
|------|---------|-----------|-----------|-------------|--------------|
| **Tokens** | **65,011** | **50,099** ⭐ | **186,132** | **191,071** | **191,948** |
| LLM 调用 | 10 | 7 | 16 | 16 | 16 |
| 迭代 | 10 | 7 | 16 | 16 | 16 |

> **发现**：Sonnet 多轮 Token 是 GPT 的 **2.86x**。与 Kimi 类似，WP 对 Sonnet 无正面效果，三组差异 < 3%。

### 5.4 Sonnet 行为特征分析

#### 特征 1：Prompt Token 异常高

Sonnet 每次 LLM 调用的 prompt token 显著高于其他模型：
- 基础读取首轮 prompt：Sonnet ~27K vs GPT ~8.5K vs Kimi ~19K
- 原因可能与 Claude 的 tokenizer 差异有关（同样的 system prompt，Claude tokenize 后 token 数更多）

#### 特征 2：与 Kimi 行为模式相似

- 同样需要先调工具再回复（2 轮/用例基础场景）
- 同样不信任路由预览
- 但跨表写入类比 Kimi 效率低（Kimi 1 轮 vs Sonnet 1.33 轮）

#### 特征 3：WP 在跨表场景有负面影响

HYBRID 组的跨表操作 Token（114K）是 OFF 组（56K）的 **2 倍**，迭代增加 50%。这是所有模型中**唯一出现 WP 导致跨表场景显著恶化**的情况。

#### 特征 4：速度快

尽管 Token 消耗高，Sonnet 总耗时（222-227s）与 GPT（224-243s）接近，说明单次 LLM 调用延迟较低。

### 5.5 四模型综合对比（更新）

| 维度 | GPT-5.3-codex | Claude Sonnet 4.5 | Kimi K2.5 | DeepSeek-reasoner |
|------|--------------|-------------------|-----------|-------------------|
| **Agent 适配性** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐ |
| **单轮效率** | 极高（1 轮） | 中等（2 轮） | 中等（2-3 轮） | 低（2+ 轮 + 超时） |
| **子代理兼容** | ✅ | ✅ | ✅ | ❌ 超时 |
| **工具失败率** | 0% | 0% | 0% | ~8% |
| **路由预览利用** | 直接采信 | 不信任 | 不信任 | 不信任 |
| **WP 收益** | **-15%~-34%** | **无效/负面** | **无效 (<3%)** | **负面** |
| **每例均 Token** | ~14.9K | ~34.4K (2.3x) | ~32.5K (2.2x) | ~78.1K (5.2x) |
| **速度** | 快 | 快 | 慢 | 很慢 |
| **推荐 WP 配置** | HYBRID(flash) | **OFF** | OFF | OFF |

---

### 5.6 DeepSeek-reasoner 适配建议

若需支持 DeepSeek-reasoner 作为主模型：
1. **关闭或大幅放宽子代理限制**：`subagent_max_iterations` 从 4/6 提高到 12+
2. **窗口感知建议关闭**：HYBRID 模式在 DS 下适得其反
3. **考虑改用 `deepseek-chat`**：非推理版更适合 Agent 的快速决策循环
4. **提高 advisor 超时**：从 800ms 至少提高到 3000ms

### 5.4 后续优化方向

1. **动态 Advisor 模型切换**：根据对话轮次自动选择 flash/pro
2. **模型适配层**：针对不同主模型自动调整子代理超时和迭代限制
3. **Advisor 超时自适应**：根据主模型响应速度动态调整 advisor 超时
4. **更大规模测试**：增加更多套件和用例，验证统计显著性
